# 딥러닝 및 이미지 파운데이션 모델
## “이미지 파운데이션 모델”

---

## 📘 CONTENTS
1. AI 파운데이션 모델 개념 및 대표 모델  
2. Vision-Language Model (VLM)  
3. Small VLM과 파운데이션 모델들 소개  
4. 개인화, 합성 데이터 활용 사례  

---

## 1차시  
### AI 파운데이션 모델 개념 및 대표 모델

---

## 학습 시작

- 학습데이터와 계산 리소스가 부족한 가난한 AI 서비스 회사(개발자)가  
  멋진 이미지 기반 AI 서비스를 개발하고자 합니다.  
  **어디서부터 시작하면 좋을까요?**

- 기존 이미지 AI 모델은 학습된 도메인과 유사한 데이터에서만 잘 작동했습니다.  
  그러나 실제 사용자 서비스는 전혀 예측하지 못한 데이터가 주어지는 경우도 많습니다.  
  학습하지 않은 상황에서도 동작하는 서비스를 개발하고자 할 때,  
  **어떤 특징을 갖는 이미지 AI 모델이 필요할까요?**

- **실용적인 이미지 AI 모델**을 가지고 어떤 서비스를 만들 수 있을까요?

---

## 학습 목표

- **AI 파운데이션 모델의 개념을 이해하고, 특징을 설명할 수 있다.**  
- **Pre-training, Fine-tuning, Zero/Few-shot 개념을 구분할 수 있다.**  
- **기존 머신러닝 모델과의 차이를 이해할 수 있다.**  
- **대표적 AI 파운데이션 모델 중 하나인 CLIP 모델의 개념과 역량을 알아본다.**

---

## AI 파운데이션 모델의 개념

---

## 1-1. 파운데이션 모델(Foundation model)이란?

### ▍AI 모델
- 함수 또는 프로그램  
- 입출력을 연결해주는 함수 + 데이터로 학습된 함수 +  
  **학습 때 보지 못했던 데이터에 대해서도 작동해야 하는 의무**
- 예시 : 뉴럴넷  
  - 입력 → 뉴럴넷 → 출력  

(이미지: dog/cat 분류를 수행하는 Neural Network 구조)

---

## 1-1. 파운데이션 모델(Foundation model)이란?

### ▍이상적인 AI 모델
- 만약 AI모델이 이 세상에서 발생 가능한 **모든 데이터**와  
  **각 데이터의 설명**을 모두 기억하고 있다면?

(이미지: 로봇이 데이터를 관찰하며 모든 이미지를 기억하는 모습)

### ▍이상적인 AI 모델
- 만약 AI모델이 세상의 모든 데이터와 설명을 기억하고 있다면?  
- 내가 얻고 싶은 답과 유사한 답이 이미 DB에 저장되어 있을 확률이 높음 →  
  **검색 엔진과 유사**
- 예시: 최근접 이웃 탐색 (Nearest Neighbor Search) 알고리즘  
- 그러나, 데이터 확보·저장·탐색은 매우 비용이 크고 현실적이지 않음

(이미지: Database와 Search Engine 구조 예시)

### ▍현실적인 기계학습 모델
- 학습 = AI모델에 데이터를 **패턴화**하여 **압축**  
- 이 과정에서 비슷함과 다름을 파악하게 되고,  
  패턴을 익히면서 새로운 데이터에 대한 **일반화 능력**이 생김  
- → **세상의 수많은 데이터를 최대한 기억할 수 있다면?**

(이미지: Neural Network가 여러 이미지를 압축하며 학습하는 모습)

---

# 1-1. 파운데이션 모델(Foundation model)이란?

▍파운데이션 모델이란?

• 대규모 데이터를 폭넓게 학습한 후, 다양한 문제에 빠르게 적용할 수 있는 범용 대형 AI 모델  
• 미국 스탠포드 대학 사람 중심 AI 연구소에서 2021년 출간된 보고서에서 새로운 범주로 구분을 시작  

▍파운데이션 모델  

• 기존 딥러닝 개발 패러다임 : 아기와 같이 언어, 시각, 청각, 촉각 등 기본적인 것들부터 배워 나가야 함  
• 파운데이션 모델 패러다임 : 거대 모델(커다란 뇌) + 대규모 데이터 학습 (많은 지식과 경험) 기반  
▷ 새로운 일을 처음 접해도 금방 배우고 잘할 수 있음  

▍파운데이션 모델  

• 파운데이션 모델 기반 개발 프로세스  

▍파운데이션 모델의 특징

특징 1 [대규모] : 트랜스포머 모델 + 대규모 언어 데이터 학습  
• 테스트에 상관없이 비슷한 패턴들이 등장하고 있음  
• 주로 비지도학습으로 훈련된 모델들도 많이 등장  
  - 의미하는 바 : 쉬운 데이터 수집 + 대규모 학습  

특징 2 [적응성] : 높은 파인튜닝 성능 (높은 태스크 적용 성능)  
• 믿고 쓸 수 있는 모델  

특징 3 [범용성] : 다양한 작업, 한정되지 않는 출력 지원  
• 예시 - 물체 판별  
  - 기존 : 20여개의 물체 종류 구분  
  - 파운데이션 모델 : 만 개 이상을 물체 종류 구분  
  (또는 자연어 기반의 한정되지 않은 대상에 대한 인식)  

▍파운데이션 모델에 의한 AI 모델 개발의 변화  

• 과거에는 매번 모델을 새로 학습했지만, 이제는 잘 학습된 모델들을 얼마나 잘 활용하느냐가 핵심  
• 파운데이션 모델 하나 확보하는데 투여되는 계산 리소스는 일부 대규모 인프라 이외에 불가  

---

▍적용 활용

활용 되는 기법들: 프롬프트 {엔지니어링, 튜닝}, 전이학습, 적용(Adaptation)학습, 파인튜닝  

- Zero-shot : 처음 보는 문제를 추가 학습 없이 바로 적용 (모델 자체가 가진 배경 지식 활용)  
- Few-shot : 예제 몇 개만 보여주면 바로 적용 가능  
- Fine-tuning : 처음부터 배우지 않아도, 조금만 알려주면 금방 적용  
  (모델 자체를 업데이트. 모델 가중치가 변경 됨)  

---

# 대표적 AI 파운데이션 모델  
- CLIP -

---

# AGI를 향해서

▍Human’s Intelligence (cognition) = perception ∪ higher cognitive processes  

• AI는 사람의 지능과 유사점/차이점 분석을 통해 발전  

▍Human’s Intelligence (cognition) = perception ∪ higher cognitive processes  

• 2022년 11월 이전 : 각 분야별로 지능의 매우 부분적 능력만을 개별적으로 모델링 시도  
• 2022년 11월 (ChatGPT) 이후 : 대규모 언어모델(LLM)이 높은 사고/추론 성능을 보여주기 시작  
  (다양한 인지 능력 벤치마크에서 인간 수준 근접)  

⇒ 그러나 사고 능력과 언어 능력 만으로 현실 세계를 이해하기에 충분할까?  

---

# LLM에 눈을 달아볼까? (시각언어모델)

사용자 : “누가 이 그림을 그렸어?”  
AI : “이 그림은 모나리자로 알려진 여성을 그린 레오나르도 다빈치의 유명한 그림입니다. 여성의 신비로운 미소를 보여주는 초상화로, 세계에서 가장 유명하고 상징적인 예술작품 중 하나가 되었습니다. …”  

입력: “이 이미지를 설명해줘”  
출력: “빨간 스카프를 두르고 있는 고양이 사진이에요.”  

---

# 시각언어모델 예시 - ChatGPT with GPT-4

▍GPT-4 (2023)

• 자연어 입력에 국한된 기존의 거대 언어 모델에서 더 나아가 이미지, 문서, 음성 등  
  멀티모달(multi-modal) 데이터를 처리할 수 있는 모델  
• GPT-4 API를 활용하여 다양한 도메인의 이미지 데이터와 결합한 모델이 개발됨 (예시 : 제조 AI)  

예시) GPT-4V for Generic Anomaly Detection  

유저  
왼쪽 이미지가 결함을 가지고 있는지 판단해줘. 만약 결함이 있다면, 구체적인 이유를 제공해줘.  

GPT-4  
이미지는 병이나 용기의 상단 부분으로 보이는 원형 물체 안으로 끈이나 줄이 통과하고 있는 것처럼 보입니다.  
검토 결과  
1. 원형 물체의 가장자리에 이물질이나 입자가 보입니다.  
2. 가장자리에는 굵은 자국이 보입니다.  
3. 줄에는 헤지거나 마모된 부분처럼 보이는 불규칙한 부분이 있습니다.  

# 시각언어모델 예시 - ChatGPT with GPT-4

▍GPT-4의 시각언어 멀티모달 언어모델로써의 능력 시연 [Sketch-to-web page (HTML)]

---

# 시각언어모델 예시 - Computer use, Claude

▍Claude 기반 Computer use 기능 시연 - 친구와의 여행 플랜 세우기  
• 수많은 컴퓨터 프로그램의 다양한 인터페이스를 이해하기 위해서는 시각 이해도 필요  

---

# 눈으로 어떤 것을 쓸까? CLIP(2021) by OpenAI

▍CLIP(2021) by OpenAI  

• 언어와 이미지의 유사도 학습  

• CLIP 모델 구조  

---

# 1-1. CLIP (2021)

▍CLIP: Contrastive Language-Image Pre-training, by OpenAI  

• AI가 언어와 시각을 통합해서 이해하는 방식을 보여준 패러다임 전환 제시  

• 파운데이션 모델로써의 특징  
  - 입력: 학습하지 않은 새로운 도메인의 입력 데이터에 대해서도 좋은 성능을 발휘 (제로샷 전이)  
  - 출력: 자연어를 이용해 한 번도 본 적 없는 카테고리도 텍스트 설명만으로 출력 정의 가능 (언어 인터페이스)  

▍대조 학습 기반(Contrastive Pre-training)의 언어-이미지 사전 학습  

• 인터넷 데이터를 통한 지도 학습(supervised learning)을 통해 자연어 기반 시각 개념 학습  
• 다양한 이미지-자연어 쌍으로 학습  
  - 인터넷에서 수집된 수억개의 이미지·텍스트 쌍  
  - Alt-text HTML tag, 이미지 캡션, 제목 등을 기반으로 수집  
  - 데이터 정제 과정을 거침 (중복 이미지, 해상도/품질 낮은 이미지, 짧은 텍스트 등)  

• 다양한 이미지-자연어 쌍으로 학습  
  - 텍스트 인코더 : Transformer  
  - 이미지 인코더 : ViT-B (또는 ResNet50)  

---

# 1-2. CLIP 구조 - 텍스트 인코더 (Transformer 기반 Text Encoder)

▍Remind - Transformer  

• 트랜스포머 구조 = 인코더 (Encoder) + 디코더 (Decoder)  
• CLIP에서는 Encoder only 구조 사용  

▍Remind - Transformer  

• 토큰이라는 단위의 입력  
• 입력된 토큰 간의 관계성을 집중하는 Attention 메커니즘으로 구성  
• L 길이의 입력 토큰은 D-차원 특징벡터(임베딩)의 배열로 형태로 입력 (L x D)  

• 자연어 데이터 :  
  Sub-word 단위의 임베딩  

---

# 1-3. CLIP 구조 - 이미지 인코더 (ViT: Vision Transformer, 2020)

▍Remind - Vision Transformer  

• 입력 구성  
  - 텍스트 인코더 (자연어 데이터 입력): Sub-word 단위의 임베딩  
  - 이미지 인코더 (이미지 데이터 입력): 패치 단위의 임베딩  
• ViT: 비전 분야에 트랜스포머를 (최소 수정으로) 적용한 모델  


▍Remind - Vision Transformer

• 이미지를 작은 패치(16x16x3)로 나눔  
• 각 패치를 1D로 Flatten  
• Learnable position embedding 사용  
  - 이미지 내에서 각 패치의 위치 민감 정보 추가  
  - 모델 학습 과정에서 함께 학습됨  
• Transformer encoder : 패치 처리  
• MLP Head를 통해 분류 작업 수행  
  - Head를 수정하여 다른 작업을 위한 transfer learning 활용 가능  
  - CLIP에서는 CLIP 학습법으로 학습됨  

---

# 1-4. CLIP (2021) 학습

▍대조 학습 (Contrastive learning)

• 학습 기준  
  - 목표 이미지(앵커)를 대응하는 텍스트(양성)와 가깝게  
  - 일치하지 않는 여러 텍스트(음성)와는 멀게  

▍대조 학습 (Contrastive learning)

Numpy-like pseudocode  

```
# image_encoder  - ResNet or Vision Transformer
# text_encoder   - CBOW or Text Transformer
# I[n, h, w, c]  - minibatch of aligned images
# T[n, l]        - minibatch of aligned texts
# W_i[d_i, d_e]  - learned proj of image to embed
# W_t[d_t, d_e]  - learned proj of text to embed
# t              - learned temperature parameter

# extract feature representations of each modality
I_f = image_encoder(I)  #[n, d_i]
T_f = text_encoder(T)   #[n, d_t]

# joint multimodal embedding [n, d_e]
I_e = l2_normalize(np.dot(I_f, W_i), axis=1)
T_e = l2_normalize(np.dot(T_f, W_t), axis=1)

# scaled pairwise cosine similarities [n, n]
logits = np.dot(I_e, T_e.T) * np.exp(t)

# symmetric loss function
labels = np.arange(n)
loss_i = cross_entropy_loss(logits, labels, axis=0)
loss_t = cross_entropy_loss(logits, labels, axis=1)
loss   = (loss_i + loss_t) / 2
```

▍대조 학습 (Contrastive learning)

*️⃣ 𝑠ᵢⱼ : i번째 이미지와 j번째 텍스트 임베딩 간의 코사인 유사도  

Softmax 기반 손실 계산  

---

# 1-4. CLIP 간단 응용

▍제로샷 이미지 인식기  

• 텍스트로 원하는 물체 카테고리 리스트 준비  
• 텍스트 기반 카테고리 리스트를 텍스트 임베딩으로 변환하여 Vector DB 준비  
• 쿼리 이미지와 비교해서 가장 높은 점수의 카테고리 반환  

▍생각해보기  
- 검색 시스템과 유사성은 무엇일까?  
- 카테고리 이외에 어떤 것이 가능할까?  
- 카테고리가 정말 많을 경우에 어떻게 효율화할까?  

---

# 강의 정리

▍오늘 공부한 내용 요약 및 정리

• 파운데이션 모델은 대규모 데이터로 사전학습된 범용 모델  
• 파운데이션 모델의 방대한 사전 지식을 이용해 다양한 태스크에 빠르게 적용 가능  
  - 장점: 데이터/리소스 효율적, 범용성, 확장성, 높은 성능  
• 파운데이션 모델은 대규모, 적응성, 범용성의 특징을 가짐  
• 대표 이미지 파운데이션 모델:  
  인터넷 상의 대규모 {텍스트, 이미지} 페어 데이터를 활용한 이미지-언어 연관성을 학습한  
  CLIP 파운데이션 모델과 그 제로샷 이미지 인식기 응용  

---

# 2차시  
Vision-Language Model (VLM)

---

# 학습 시작

• 주어진 이미지와 장면을 분석하고 이해하는 서비스를 만들기 위해  
  지금까지 배운 이미지 인식기, 물체 탐지 모델로 충분할까?  
  인식/탐지 태스크 출력의 제한  

• 세상에 존재하는 수많은 케이스들을 이해하고,  
  사용자의 요구에 맞춰 이미지를 분석할 수 있는 진짜 인텔리전트한 모델은 없을까?  

• 나 대신 어려운 그래프와 문서들을 이해하고 컨설팅 해주는 모델은 어떻게 만들지?  

• 나와 같은 것을 "보고" "대화"를 나눌 수 있는 AI 모델을 구축해보자!  

---

# 학습 목표

• 고도화된 CLIP 계열인 SigLIP의 등장 배경에 대해서 이해한다.  
• Vision-Language Model의 구조 및 구축 패턴에 대해서 파악한다.  
• LLaVA, Qwen-VL, InternVL 등 최신 시각-언어 파운데이션 모델들의  
  발전 동향에 대해서 설명할 수 있다.  
• (심화) 추가 학습을 요구하지 않는 CLIP계열 멀티모달 정합 모델의 심화 응용 사례를 파악한다.  

# Vision-Language Models

---

## 3-1. AGI를 향해서

▍Human’s Intelligence (cognition)
= perception ∪ higher cognitive processes

# 1. 학습 전략의 중요성

---

## 1-1. 모델 구조

### ▪ 지난 1차/2차 강의의 내용 요약
- CNN 구조와 발전 (AlexNet → ResNet → MobileNet)  
- CNN의 한계 → RNN, Transformer (ViT)

### ▪ CNN의 구성
- 합성곱 레이어  
- 풀링  
- 비선형 함수  
- 정규화  
- 연결층 레이어  

---

## 1-2. 좋은 모델 구조 = 우수한 성능?

### ▪ 좋은 구조만으로는 성능 보장 불가!
- 동일한 구조, 동일한 데이터셋을 사용해도 성능 차이가 큼  
- 이유: 학습 과정에서 발생하는 불안정성, 과적합, 수렴 속도 문제  

### ▪ 학습에서 자주 겪는 문제들
- **학습 불안정:** 손실 폭발, 학습 멈춤, 수렴 실패  
  - 손실 폭발: 학습 과정에서 손실 값이 급격히 커져 모델이 수렴하지 못하는 현상  
  - 학습 멈춤: 손실 값이 더 이상 줄지 않고 학습이 정체되는 상황  
  - 수렴 실패: 최적의 값에 도달하지 못하고 학습이 무의미하게 끝나는 현상  
- **과적합:** 훈련 데이터에는 맞지만 검증·실전 성능 저하  
  - 원인: 데이터 부족, 모델 복잡도 과다, 정규화 부족 등  
- **느린 수렴:** 최적점에 도달하기까지 불필요하게 많은 epoch 소모로 인한 학습 효율 저하  

---

## 1-3. 학습 전략

### ▪ 본 강의의 해결 방향
- 구조 설계만큼 중요한 훈련 전략 제시  
- 세부 방법 (예시)  
  - 학습률 스케줄링, 정규화, 초기화, 데이터 전처리 등  

### ▪ 적용 시 기대 효과
- 일반화 성능 + 학습 효율성 확보  

---

> **좋은 구조만으로는 충분하지 않다 → 훈련 전략이 필요하다**

---

# 2. 모델 구성: 악마는 디테일에 있다

---

## 2-1. 활성화 함수

### ▪ 정의
- 입력 신호의 총합을 출력 신호로 변환하는 함수  
  - 예시: 뉴런이 ‘켜질지 / 얼마나 반응할지’를 결정하는 스위치  

---

## ▪ 역할
- 신경망에 비선형성 부여 → 복잡한 패턴 학습 가능  
  - 단순 패턴은 선형 분류가 가능하지만, 복잡한 패턴은 직선만으로 분류 불가능  
  - 활성화 함수를 통해 비선형성을 부여함으로써 복잡한 패턴 학습 가능  

---

## ▪ 활성화 함수 선택

### ▪ 역할
- 신경망에 비선형성 부여 → 복잡한 패턴 학습 가능  
- 활성화 함수가 없다면 단순 선형모델과 동일  
- 단, 활성화 함수의 특성에 따라 학습 안정성과 성능이 크게 좌우됨  
  - 활성화 함수 종류: Sigmoid, Tanh, ReLU, Leaky ReLU 등  

# 대표 활성화 함수 : Sigmoid

---

## Sigmoid
- 0~1 사이 값으로 출력 값을 제어 → 확률 값처럼 해석 가능
  - 분류 문제(특히 이진 분류)에서 “이 클래스일 확률”로 활용 가능
  - 이진 분류 예시: 합격/불합격, 참/거짓

### ▪ 함수  
\( a(x) = \frac{1}{1 + e^{-x}} \)  
- 출력은 항상 0~1 사이  

## 문제①
- \( a(x) = \frac{1}{1 + e^{-x}} \)
- Sigmoid 함수는 입력이 매우 크거나 매우 작으면 출력이 거의 0이나 1에 고정  
  → 더 이상 역전파 전달 X  
  - 역전파: 정답과 예측의 차이(오답률)를 모델에 전달하며 가중치를 수정하는 과정  
  - 출력이 0이나 1인 구간에서 역전파 신호가 0이 되어 신경망이 더 이상 학습을 못함  

## 문제②
- \( a(x) = \frac{1}{1 + e^{-x}} \)
- Sigmoid 출력 범위는 항상 양수  
  → 학습 과정에서 편향된 업데이트 발생  
  - 기울기의 평균이 한쪽(양수)으로 치우쳐 학습 비효율 발생  

## 문제③
- 계산식에 지수 함수(exp)가 들어감  
  → ReLU처럼 단순한 max 연산보다 계산 비용이 더 큼  

### ▪ Sigmoid 정의식  
\( a(x) = \frac{1}{1 + e^{-x}} \)

### ▪ ReLU 정의식  
\( f(x) = \max(0, x) \)

---

# 대표 활성화 함수 : Tanh

---

## 출력 범위
- [-1, 1]

## 역할
- 데이터가 중심(0)을 기준으로 대칭 → 학습 안정성 ↑  
  - 음수/양수 모두 표현 가능 → Sigmoid보다 효과적  

## 문제①
- 기울기 소실 문제 여전 → 학습 정체  
  - 출력이 -1이나 1에 가까워져 신경망이 더 이상 학습 불가  

## 문제②
- exp 연산 포함 → 계산 비용이 큼  

### ▪ Tanh 정의식  
\( \tanh(x) = \frac{e^{x} - e^{-x}}{e^{x} + e^{-x}} \)

---

# 대표 활성화 함수 : ReLU

---

## ReLU (Rectified Linear Unit)
\( f(x) = \max(0, x) \)

### ▪ 장점
- 양의 영역에서 포화되지 않음 → Sigmoid/tanh처럼 기울기 소실 문제 크게 줄어듦  
  - 입력이 음수면 0, 양수면 그대로 출력함  
- 계산 효율성 높음 → 단순 max(0, x) 연산, 매우 빠름  
- 학습 속도 빠름 → 실제로 Sigmoid, tanh 대비 6배 이상 빠른 수렴 보고됨  

## 문제점
- 죽은 뉴런 문제 → 입력이 계속 음수면 뉴런이 0만 출력 → 영구적으로 “죽은 뉴런” 발생  
  - 죽은 뉴런은 가중치 업데이트(학습)를 멈춤  
- ‘0’을 기준으로 비대칭  

---

# 대표 활성화 함수 : Leaky ReLU

---

## Leaky ReLU
\( f(x) = \max(0.01x, x) \)

### ▪ 장점
- ReLU의 모든 장점 수용  
- 죽지 않는 뉴런 (Dead ReLU 문제 해결)  
  → 음수 입력에도 작은 기울기를 부여해 뉴런이 완전히 죽지 않음  

## 문제점
- 음수 영역 기울기 값(0.01) 설정의 임의성  
  - 너무 작으면 여전히 기울기 소실, 너무 크면 출력 왜곡 가능  
- ‘0’ 중심 대칭이 아님  
  - 신호가 한쪽(양수)으로 치우치는 경향 발생 가능  
- 항상 ReLU보다 우세하지 않음  
  - 일부 문제에서는 성능 차이가 거의 없음  

# 대표 활성화 함수 : ELU

---

## Exponential Linear Unit (ELU)
\[
f(x) = 
\begin{cases}
x & \text{if } x > 0 \\
\alpha(\exp(x) - 1) & \text{if } x \le 0
\end{cases}
\]

---

### ▪ 장점
- ReLU의 모든 장점 수용!  
- 평균 출력이 0 근처에 위치  
- 음수 영역에서의 포화 구간 제공 → 기울기 소실은 막고, 왜곡 문제도 해결  

---

## Exponential Linear Unit (ELU)
\[
f(x) = 
\begin{cases}
x & \text{if } x > 0 \\
\alpha(\exp(x) - 1) & \text{if } x \le 0
\end{cases}
\]

---

### ▪ 문제점
- 계산 복잡성 증가  
- 하이퍼파라미터 α 설정 필요  
  → 음수 영역 기울기의 크기를 결정하는 α 값에 따라 성능 차이 발생  

---

# 다양한 활성화 함수

---

## 다양한 활성화 함수

| 함수 | 수식 |
|------|------|
| Sigmoid | \( \sigma(x) = \frac{1}{1+e^{-x}} \) |
| tanh | \( \tanh(x) \) |
| ReLU | \( \max(0, x) \) |
| Maxout | \( \max(w_1^T x + b_1, w_2^T x + b_2) \) |
| Leaky ReLU | \( \max(0.1x, x) \) |
| ELU | \( \begin{cases} x & x \ge 0 \\ \alpha(e^x - 1) & x < 0 \end{cases} \) |
| SELU | \( \begin{cases} \lambda x & x < 0 \\ \lambda(\alpha e^x - \alpha) & \text{otherwise} \end{cases} \) |

---

# 결론은?

---

## ▪ 큰 고민 말고, 일단 ReLU부터 시도!
\[
\text{ReLU: } \max(0, x)
\]

- 성능 경쟁 중이라면, ReLU의 개선판을 시도  

| 함수 | 수식 |
|------|------|
| ReLU | \( \max(0, x) \) |
| Leaky ReLU | \( \max(0.1x, x) \) |
| ELU | \( \begin{cases} x & x \ge 0 \\ \alpha(e^x - 1) & x < 0 \end{cases} \) |
| SELU | \( \begin{cases} \lambda x & x < 0 \\ \lambda(\alpha e^x - \alpha) & \text{otherwise} \end{cases} \) |

- Sigmoid나 Tanh는 전문가 영역!  

| 함수 | 수식 |
|------|------|
| Sigmoid | \( \sigma(x) = \frac{1}{1 + e^{-x}} \) |
| tanh | \( \tanh(x) \) |

---

# 2.2. 데이터 전처리

---

# 데이터 형식 통일

---

## ▪ 이미지 조건을 일치
- 학습/검증/테스트에 모두 동일하게 적용  
  - 이미지 해상도  
  - 색상 (예: RGB or BGR or Grey)  
  - 밝기  
  - 정규화  

---

## ▪ 일반적 정규화 방식
- 평균 0, 표준편차 1로 정규화 — 중요!!!

---

# 데이터 형식 통일

---

## ▪ 이미지 조건을 일치

### 색상 채널 통일 단계 예시  
3-channel 이미지 → 모델 입력 크기 고정  

```python
basic_rgb_pipeline = transforms.Compose([
    transforms.Resize(256, interpolation=InterpolationMode.BICUBIC),  # 크기 통일
    transforms.CenterCrop(224),  # 센터 크롭 (선택)
    transforms.ToTensor(),  # 텐서화
    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)  # 정규화
])
```

Grayscale 이미지 → 모델 호환 위해 3-channel로 복제  

```python
grayscale_pipeline = transforms.Compose([
    transforms.Resize(256, interpolation=InterpolationMode.BICUBIC),
    transforms.CenterCrop(224),
    transforms.Grayscale(num_output_channels=3),  # (H,W) -> (3,H,W)
    transforms.ToTensor(),
    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)
])
```

# 모델별 전처리 방식 예시

---

## ▪ AlexNet
- **평균 이미지를 빼기**
  - 학습 데이터 전체의 평균 이미지를 입력 이미지에서 이를 빼줌
  - 평균 이미지는 크기가 [32, 32, 3] 배열 형태

---

## ▪ VGG
- **채널별 평균 빼기**
  - R, G, B 각 채널의 평균 값을 계산, 입력에서 각 채널별 평균값을 빼줌

---

## ▪ ResNet
- **평균 빼기 + 채널별 표준편차로 나누기**
  - R, G, B 각 채널의 평균을 빼고, 표준편차로 나눔

---

# 2.3. 모델 상수 초기화

---

# 아이디어1: 0으로 초기화

---

## ▪ 모든 가중치(W)와 편향(b)을 0으로 초기화하면 무슨 일이 생길까?

- 모든 출력은 0  
  \[
  y = W \cdot x + b
  \]
- 뉴런 별 출력 \( y \) 동일, 기울기 \( \frac{\partial L}{\partial y} \) 동일  
  → 학습이 이뤄지지 않는다  

---

# 아이디어2: 임의(랜덤) 초기화

---

## ▪ 랜덤 초기화는?
- 작은 랜덤 숫자 (0.01 곱 → 0.01 분산): Gaussian 분포를 따름, 0을 중심으로  

### ▪ Gaussian 분포
- 종 모양의 정규 분포로, 평균 0 근처 값이 가장 자주 발생  
  → 값이 너무 크거나 작아지는 걸 막을 수 있음  

```python
W = 0.01 * np.random.randn(Din, Dout)
```

---

## ▪ 깊지 않은 모델에서는 동작하는 전략!

- \( W = 0.01 * np.random.randn(Din, Dout) \)
- 작은 랜덤 값으로 초기화하면 적절히 동작  
- 그러나 깊은 모델에서는 다른 문제가 발생  

---

## ▪ 깊은 모델은?

- \( W, b \)가 작은 수(<1)에 분포함  
  → 역전파 시 기울기를 구하는 과정에서 W를 계속 곱하면서 **기울기가 0으로 수렴**
- 반대로 상수가 크면(>1) **기울기는 폭발**

---

# 아이디어3: 자비에 초기화

---

## ▪ 자비에(Xavier) 초기화
- 가중치 초기 분포의 분산을 입력 차원으로 맞춤  
  \[
  \text{std} = \frac{1}{\sqrt{Din}}
  \]
  ```python
  W = np.random.randn(Din, Dout) / np.sqrt(Din)
  ```

---

## ▪ 분산을 입력 차원(뉴런 수) 증가를 고려하여 설계
- 모델 상수 분산이 입력 차원과 같으면, 선형연산 이후 출력의 분산 ≈ 입력의 분산  

```python
W = np.random.randn(Din, Dout)/np.sqrt(Din)
x = np.tanh(x.dot(W))
```

---

# 아이디어4: 허 초기화

---

## ▪ 자비에 초기화 + ReLU의 궁합?
- 가중치 초기 분포의 분산을 입력 차원으로 맞춤  
  \[
  \text{std} = \frac{1}{\sqrt{Din}}
  \]
  ```python
  W = np.random.randn(Din, Dout)/np.sqrt(Din)
  x = np.maximum(0, x.dot(W))
  ```

---

### ▪ 자비에에서는 입력력 분산을 맞추는 전략은 입력력이 대칭적 분포를 보인다는 가정 하에서 설계
- ReLU는 양의 분포만 남김 → **비대칭 분포**
- 입력 분포의 절반만 활성화 → 분산 불균형 발생  

# 모델별 전처리 방식 예시

---

## ▪ AlexNet
- **평균 이미지를 빼기**
  - 학습 데이터 전체의 평균 이미지를 입력 이미지에서 이를 빼줌
  - 평균 이미지는 크기가 [32, 32, 3] 배열 형태

---

## ▪ VGG
- **채널별 평균 빼기**
  - R, G, B 각 채널의 평균 값을 계산, 입력에서 각 채널별 평균값을 빼줌

---

## ▪ ResNet
- **평균 빼기 + 채널별 표준편차로 나누기**
  - R, G, B 각 채널의 평균을 빼고, 표준편차로 나눔

---

# 2.3. 모델 상수 초기화

---

# 아이디어1: 0으로 초기화

---

## ▪ 모든 가중치(W)와 편향(b)을 0으로 초기화하면 무슨 일이 생길까?

- 모든 출력은 0  
  \[
  y = W \cdot x + b
  \]
- 뉴런 별 출력 \( y \) 동일, 기울기 \( \frac{\partial L}{\partial y} \) 동일  
  → 학습이 이뤄지지 않는다  

---

# 아이디어2: 임의(랜덤) 초기화

---

## ▪ 랜덤 초기화는?
- 작은 랜덤 숫자 (0.01 곱 → 0.01 분산): Gaussian 분포를 따름, 0을 중심으로  

### ▪ Gaussian 분포
- 종 모양의 정규 분포로, 평균 0 근처 값이 가장 자주 발생  
  → 값이 너무 크거나 작아지는 걸 막을 수 있음  

```python
W = 0.01 * np.random.randn(Din, Dout)
```

---

## ▪ 깊지 않은 모델에서는 동작하는 전략!

- \( W = 0.01 * np.random.randn(Din, Dout) \)
- 작은 랜덤 값으로 초기화하면 적절히 동작  
- 그러나 깊은 모델에서는 다른 문제가 발생  

---

## ▪ 깊은 모델은?

- \( W, b \)가 작은 수(<1)에 분포함  
  → 역전파 시 기울기를 구하는 과정에서 W를 계속 곱하면서 **기울기가 0으로 수렴**
- 반대로 상수가 크면(>1) **기울기는 폭발**

---

# 아이디어3: 자비에 초기화

---

## ▪ 자비에(Xavier) 초기화
- 가중치 초기 분포의 분산을 입력 차원으로 맞춤  
  \[
  \text{std} = \frac{1}{\sqrt{Din}}
  \]
  ```python
  W = np.random.randn(Din, Dout) / np.sqrt(Din)
  ```

---

## ▪ 분산을 입력 차원(뉴런 수) 증가를 고려하여 설계
- 모델 상수 분산이 입력 차원과 같으면, 선형연산 이후 출력의 분산 ≈ 입력의 분산  

```python
W = np.random.randn(Din, Dout)/np.sqrt(Din)
x = np.tanh(x.dot(W))
```

---

# 아이디어4: 허 초기화

---

## ▪ 자비에 초기화 + ReLU의 궁합?
- 가중치 초기 분포의 분산을 입력 차원으로 맞춤  
  \[
  \text{std} = \frac{1}{\sqrt{Din}}
  \]
  ```python
  W = np.random.randn(Din, Dout)/np.sqrt(Din)
  x = np.maximum(0, x.dot(W))
  ```

---

### ▪ 자비에에서는 입력력 분산을 맞추는 전략은 입력력이 대칭적 분포를 보인다는 가정 하에서 설계
- ReLU는 양의 분포만 남김 → **비대칭 분포**
- 입력 분포의 절반만 활성화 → 분산 불균형 발생  

---

## ▪ He 초기화
- 가중치 초기 분포의 분산을 **2 × 입력 차원**으로 맞춤  
  \[
  \text{std} = \sqrt{\frac{2}{Din}}
  \]
  ```python
  W = np.random.randn(Din, Dout) * np.sqrt(2) / np.sqrt(Din)
  x = np.maximum(0, x.dot(W))
  ```

- **ReLU 비대칭성**을 고려하여, 유사 분산이 레이어 후반에도 유지됨  

---

# RestNet의 등장 배경

---

## ▪ RestNet (Residual Network)
- **잔차 연결(skip connection)** 을 사용하여 매우 깊은 신경망도 안정적으로 학습할 수 있는 구조  
  - 입력을 출력에 더해주는 “지름길(skip)”로, 네트워크가 전체를 새로 배우지 않고 **변화량만 학습**  

---

## ▪ 깊은 모델의 문제점
- 깊어질수록 **기울기 소실 / 폭발 문제** 발생 → 학습 어려움  
- RestNet은 이를 완화하는 구조로 설계됨  

---

# 주의사항: ResNet

---

## ▪ ResNet 철학 — 전층의 기울기 전달
- Skip connection으로 입력이 그대로 더해져, 깊은 층에서도 **기울기가 끊기지 않음**
- 그러나 **초기화가 잘못되면**, 후반 층의 출력 분포값이 계속 증폭 가능  
  → 안정적 학습이 어려워짐  

---

# 주의사항: ResNet (2)

---

## ▪ ResNet 철학 — 전층의 기울기 전달
- ReLU를 사용하는 구조이므로 **He 초기화** 사용  
- 분산 유지 조건:
  \[
  Var(x + F(x)) = Var(x)
  \]
  → 안정적인 학습을 유도  

- 두 번째 conv는 **0으로 초기화**  
- 첫 번째 conv는 **He 초기화**

---

# 주의사항: ResNet (3)

---

- 사실상 초반에는 skip에만 의존하여 안정적 학습 유도  
- 초기 입력의 분포를 그대로 유지해야 학습이 안정적으로 시작됨  

```python
첫 번째 conv → He 초기화
두 번째 conv → 0으로 초기화
```

---

# 2-4. 모델 정규화

---

# 데이터 처리 / 초기화 이후 학습 가능

---

## ▪ 학습 과정에서 드디어 오차 감소!
- Train loss ↓, Accuracy ↑  

그러나...  
### 검증 오차(val loss)가 오히려 오른다면?
→ **과적합(Overfitting)** 의 신호  

---

## ▪ 정규화를 통해 검증 오차를 줄이자!
- **정규화(Regularization)**: 모델 복잡도를 제어하여 훈련과 검증 성능의 차이를 줄이는 방법  
- **검증 오차**: 모델이 학습하지 않은 새로운 데이터에서 보이는 실제 성능 지표  

---

# 아이디어1: 가중치 감소 (Weight Decay)

---

## ▪ 목적
- 학습 과정에서 특정 가중치가 지나치게 커지는 현상 방지  

### ▪ 원인
- 가중치가 너무 크면 입력에 과도하게 반응 → 훈련 데이터에 과적합  

---

## ▪ 방법
- 가중치 크기에 비례한 패널티 적용  
- “큰 가중치는 과적합을 부른다 → 줄여주자”  

---

# 아이디어1: 가중치 감소 (2)

---

## ▪ 만약 가중치 감소만으로 완벽히 만족한다면?
- 모든 가중치가 0인 모델 → 아무것도 학습하지 않음  
- 따라서 **원본 손실(예: Cross Entropy 등)** 과 함께 사용해야 의미가 있음  

> 균형이 핵심:  
> 훈련 오차도 줄이면서 + 가중치도 적당히 작게 유지  

---

# 아이디어1: 가중치 감소 (3)

---

## ▪ L2 정규화 (Ridge, Weight Decay)
- 큰 가중치에 제곱으로 패널티 → 극단적 큰 값 방지  
- 결과: **모든 가중치가 골고루 작아짐**  
  \[
  R(W) = \sum_k \sum_l W_{k,l}^2
  \]

---

## ▪ L1 정규화 (Lasso)
- 모든 가중치에 **절댓값 크기만큼 동일한 패널티** 부여  
- 결과: **중요하지 않은 가중치는 완전히 0이 됨 → 희소한 모델**  
- 장점: 자동으로 중요한 특성만 선택 → 단순한 모델  
  \[
  R(W) = \sum_k \sum_l |W_{k,l}|
  \]

---

- **L1 정규화**는 가능한 한 더 작은 모델을 선호하는 경우 선택  
  (즉, 특성의 희소성을 유도하고 싶을 때)

# 아이디어1: 가중치 감소

---

## Elastic net (L1 + L2)

- 변수가 많고 상관관계가 높을 때 특히 효과적
- L1과 L2의 장점을 모두 활용: 특성 선택 + 안정적인 학습

\[
R(W) = \sum_k \sum_l \beta W_{k,l}^2 + |W_{k,l}|
\]

### 작동 방식
- β 파라미터로 L1과 L2의 비중 조절
- β가 크면 → L2 효과 강함 (모든 가중치 작게)
- β가 작으면 → L1 효과 강함 (희소한 모델)

---

# 아이디어2: 드롭아웃

---

## 개념
- 학습 과정에서 일부 뉴런을 확률적으로 끔(0으로 설정)
- 매 학습 스텝마다 다른 네트워크 구조가 샘플링되는 효과
- 직관: “무작위로 뉴런을 비워서 특정 뉴런/특징에 과도하게 의존하지 않게 함”

---

## 장점
- 과적합 방지 → 네트워크가 특정 패턴에 의존하지 않고 일반화 성능 ↑  
  - 훈련 시 매번 다른 뉴런 조합으로 학습하므로 특정 뉴런에 과도하게 의존하지 않음
- 여러 작은 모델을 합친 것과 비슷한 효과 (성능 개선을 위한 앙상블 방식과 유사)  
  - 앙상블: 여러 개의 서로 다른 모델을 학습시킨 후, 예측할 때 모든 모델의 결과를 평균내거나 투표하여 최종 결정
- 간단하면서도 매우 강력

---

## 단점
- 학습시간 증가
- 최적의 드롭 비율을 찾는 것이 중요
- 모델에 따라 비선호 되기도 함  
  - RNN/LSTM 등 시계열 데이터에서는 변형된 기법 필요  
  - 배치 정규화 진행된 모델에서는 비선호 (이미 강력한 정규화가 적용)

---

## 실행 단계에서 동작
- 학습 중에는 뉴런을 확률적으로 끔.  
  - 예: 드롭아웃 확률 p=0.5 (뉴런을 끌 확률) → 뉴런 절반만 살아있음 (1-0.5=0.5)
  - 실질적인 출력값이 줄어듦. (예: 평균적으로 절반 출력)

### 문제점
- 테스트 시에는 뉴런을 전부 사용
- 그대로 쓰면, 학습할 때보다 출력 크기가 2배 → 학습-추론 간 분포 차이가 생겨 성능 저하

---

## 실행단계 해결책 – Inverted 드롭아웃
- 학습 시 살아남은 뉴런의 출력을 1/(1-p) 배 스케일링  
  - 예: p=0.5 면, 활성 뉴런에 ×2

## 실행단계 해결책 – 기존 방식
- (1-p)를 출력에 곱하여 평균치를 맞춤.  
  - 예: p=0.5면 ×0.5를 테스트 출력에 스케일링

### 단점: 테스트 시 추가 연산 필요
- 매번 (1-p) 곱셈 연산  
- 실제 서비스에서 속도 저하

---

# 3. 학습 안정성 전략

---

# 3.1. 학습 비율 조정

---

# 학습 비율은 가장 중요한 하이퍼상수!

---

## 같은 모델, 같은 전처리, 같은 모듈을 사용해도 학습 비율에 따라 다른 결과!
- 잘못된 학습 비율 선택으로 학습이 완전히 실패할 수도 있음  

![loss 그래프]
- 학습률을 너무 높게 잡거나, 낮게 잡았을 경우  
  Loss(손실)가 충분히 줄어들지 않거나, 폭발하는 모습을 볼 수 있음  

---

## 학습 비율을 어떻게 선정해야 할까?
- 기본적으로 사용하는 전략: 학습 비율을 큰 값에서 시작하여, epoch 지날수록 작은 값으로 조정함
- 학습 비율을 줄이는 다양한 전략이 있음  

![loss 그래프]
Good learning rate의 경우,  
Loss(손실)가 안정적으로 줄어드는 모습을 볼 수 있음

# 학습률 계단식 변경

---

## 일정 에폭(Epoch)이 지날 때 마다 계단식으로 줄이는 방식

- 에폭: 학습 데이터를 1번 다 외움을 의미함
- K 에폭마다, 감소계수*초기 학습률 만큼 감소하는 전략임  
  - 예: η₀ = 0.1, γ = 0.1, k = 30
  - 아래 그래프는 0~29 에폭 → 0.1, 30~59 에폭 → 0.01, 60~89 에폭 → 0.001 의 학습률을 적용한 경우임

![Training Loss & Learning Rate 그래프]

---

# 학습률 코사인 변경

---

## 계단형 방식은 변경 지점을 여러개 선정, 복잡하다는 단점이 있음
- 학습 곡선이 불안정할 수 있음

### 코사인 파형에 따른 변경
- 학습률을 코사인 함수 곡선처럼 점점 줄여가는 방식  
- 직관: “처음엔 크게, 나중엔 미세하게 조율”

\[
n_t = n_0 \cdot \frac{1}{2}\left(1 + \cos\left(\frac{\pi t}{T}\right)\right)
\]

![Training Loss & Learning Rate 그래프]

---

# 학습률 선형 변경

---

## 직선을 따라 변경
- 학습률을 학습이 진행될수록 선형(직선)으로 줄여가는 방식  
- 직관: “처음엔 크게 배우고, 끝날수록 일정하게 줄여 수렴”
- 사전학습/미세조정에서 주로 쓰임

\[
n_t = n_0 \cdot \left(1 - \frac{t}{T}\right)
\]

![Training Loss & Learning Rate 그래프]

---

# 그 밖의 변경

---

## 다양한 감소 방식 가능

- 역제곱 꼴: 처음에 크게, 이후에 느리게 줄임  
  - 대규모 학습에는 부적합함  

- 일정값 유지: 동일한 속도로 학습함  
  - 데이터가 많고 과적합 위험이 없을 때 활용  

\[
\eta_t = \frac{\eta_0}{\sqrt{t}} \quad \text{or} \quad \eta_t = \eta_0
\]

![Learning Rate 그래프 2개]

---

# 학습 종료

---

## 과적합 방지를 위한 또 다른 방법

- 빠른 종료(Early Stopping) 기법  

![Loss & Accuracy 그래프]

모델이 학습하는 동안 검증 데이터셋을 통해 검증 손실을 모니터링함. (그래프 상 주황색 곡선)  
학습을 진행하면서 더 이상 성능이 좋아지지 않고, 오히려 나빠지기 시작하면 학습을 조기에 멈춤.

---

# 3.2. 하이퍼파라미터 선정

---

# 파라미터 vs 하이퍼파라미터

---

## 파라미터
- 학습을 통해 모델 스스로 얻는 값  
  - 예: 뉴럴 네트워크의 가중치, 편향 등

## 하이퍼파라미터
- 학습 전에 사용자가 정해야 하는 값
- 학습이 진행되는 동안 고정됨
- 하이퍼파라미터에는 어떤 종류가 있을까?

---

# 주요 하이퍼파라미터

---

## 학습 관련
- 학습률 → 가장 중요!, 디케이 방식 (스텝, 코사인, 선형 등)
- 배치 사이즈 (작으면 정규화 효과, 크면 안정성 효과)
- 에폭 수 (조기 종료 여부)

## 최적화 관련
- 최적화 툴 선택 (SGD, Adam, AdamW)
- 모멘텀, 최적화 계수
- 가중치 감소 (L2, L1)

## 모델 구조 관련
- 네트워크 깊이
- 채널 수/드롭아웃 비율
- 정규화 (BN, LN, GN 등)

---

## 모델 학습 성능은 구조, 학습 방법론 못지 않게 하이퍼파라미터 선택에 크게 의존
- 어떤 값의 조합이 최적일지 알 수 없어 탐색이 필요

### 하이퍼파라미터 값을 탐색하는 방식

#### ▪ 그리드 탐색
- 하이퍼파라미터 후보들을 격자처럼 전부 조합해보는 방식임

#### ▪ 랜덤 탐색
- 하이퍼파라미터 공간에서 무작위로 값을 선택해 탐색함  
- 성능에 크게 영향을 주지 않는 불필요한 축의 값에 경우의 수를 실험하지 않아도 되어 시간을 낭비하지 않을 수 있음

![Grid Layout vs Random Layout 이미지]

---

# 하이퍼파라미터 선택 비법

---

## 모든 조합을 다 실험할 수 없다면?
- 빅테크에서조차 모든 조합을 실험하지 않음.
  - 그들도 많은 프로젝트를 진행하고 있으며, 모델이 매우 큼.
- 몇 가지 규칙과 직관을 활용하면 GPU가 많지 않아도 좋은 성능 도출 가능

# 체크리스트 1

---

## 데이터 입력 등 문제가 없을까?

### ▪ 초기 손실값을 확인하자
- 데이터 손실을 측정할 때, 분류 문제 등에서 많이 사용되는 손실 함수인 CE 손실이라면,  
  초기 손실은 log(C)와 유사한 수준이어야 정상임!
- 만약 예상치를 크게 벗어난다면 데이터 로딩/라벨 문제를 확인해야 함.

---

# 체크리스트 2

---

## 학습률과 초기값 확인

- 작은 샘플을 활용, 과적합 시켜보자.
  - 어떻게? 정확도 100% 달성까지 작은 학습 샘플에 대해 학습 진행  
    (정규화 X, 고의로 과적합 야기)

---

# 체크리스트 2

---

## 학습률과 초기값 확인

- 작은 샘플을 활용, 과적합 시켜보자.
  - 정확도 100% 달성까지 작은 학습 샘플에 대해 학습 진행  
    (정규화 X, 고의로 과적합 야기)

### ▪ 손실이 줄지 않는다면?
- 학습률/초기화 문제
- 모델 구조의 오류 가능성
- 활성화 함수 이슈
- 최적화 툴 이슈/코드 버그

---

## 학습률과 초기값 확인

- 작은 샘플을 활용, 과적합 시켜보자.
  - 정확도 100% 달성까지 작은 학습 샘플에 대해 학습 진행  
    (정규화 X, 고의로 과적합 야기)

### ▪ 손실이 폭발한다면?
- 학습률을 줄이고, 초기화 변경 (가장 흔한 이슈)
- 네트워크 깊이가 깊거나, 구조적 이슈 (RNN)

---

# 체크리스트 3

---

## 체크리스트 2에서 얻은 구조, 최적화 툴 활용, 학습률을 찾자.

- 모든 학습 데이터를 활용, 작은 Iteration (~100 iter) 빠르게 손실이 줄어드는 학습률을 우선 탐색함  
  - 100 iter만 학습하여 빠르게 경향을 파악

- 일반적 탐색 범위: 로그 스케일로 1e-1, 1e-2, 1e-3, 1e-4  
  → 손실이 실제로 줄어들기 시작하는 좋은 학습률 시작점을 다수 확보!

- 직관: “손실이 실제로 줄어드는 학습률부터 시작하라.”

---

# 체크리스트 4

---

## 체크리스트 3에서 얻은 후보 학습률 + 후보 가중치 변형 방식 중, 좋은 조합을 탐색

- 상기 조합을 활용, 1~5 에폭 동안 모델을 학습시켜 성능 비교

### ▪ 왜 이런 방식이 유효할까?
- 모든 조합을 끝까지 학습할 경우, 연산자원이 낭비됨.
- 좋은 조합은 초기 몇 에폭 내에 손실이 줄어듦.
- 모두 훈련하지 않고, 짧은 학습만으로 경향성 관찰 가능.
- 단, 검증 세트에서의 성능으로 관찰할 것.  
  (학습 손실만 보면 일반화 성능을 알 수 없음)

---

# 체크리스트 5

---

## 체크리스트 4에서 얻은 좋은 조합들을 활용, 10~20 에폭까지 추가 학습

- 학습률 변경(줄이기)는 적용하지 않음.

### ▪ 왜 학습률 변경을 제외할까?
- 학습률 변경은 성능을 더 개선하지만, 학습 속도는 느려짐.  
  - 탐색과정에서 속도 늦추는 방식을 쓰는 것은 비효율!

- 순수한 조합의 성능만으로 판단

---

# 체크리스트 6

---

## 학습률에 따른 손실곡선 관찰

![손실의 이동평균 그래프 / train-val 정확도 그래프]

- 손실의 이동평균 관찰  
- 학습데이터/검증데이터 모두 확인

---

## 학습률에 따른 손실곡선 관찰

![초반 손실값 유지 그래프]

- 초반 손실값이 유지되는 경우: **초기값이 문제!**

![손실 완만 그래프]

- 손실이 크게 떨어지지 않고 유지되는 경우:  
  **학습률 변경(줄이기) 시도하기**

---

학습률 변경을 적용하였는데, 이후 학습이 진행되지 않는 경우:  
**정체가 오기 전, 너무 일찍 학습률을 줄였다고 판단.**

(그래프: 손실이 급격히 줄다가 평평하게 유지)

---

## 학습률에 따른 정확도 곡선  

---

정확도가 증가할 경우:  
→ **계속 학습할 것!**

(그래프: 학습 데이터 / 검증 데이터 모두 상승 추세)

---

학습/검증 정확도가 크게 벌어진 경우:  
→ **과적합된 것! 정규화 방식을 도입해야 함.**

(그래프: 학습 데이터는 상승하지만 검증 데이터는 하락)

---

학습데이터 / 검증데이터 결과의 차이가 매우 적다면?  
→ **모델의 힘이 너무 약한 것!**  
큰 모델을 도입하여 더 오래 학습해야 함.

(그래프: 두 곡선이 거의 겹침)

---

# 확인문제  

---

① 좋은 모델 구조를 골랐는데도 학습이 실패할 수 있는 이유는?  
② Sigmoid 함수의 주요 문제는?  
③ Leaky ReLU가 ReLU와 다른 점은 무엇인가?  
④ RestNet에서 사용하는 전처리 방식은?

---

# 확인문제 정답 및 해설  

---

① 구조가 좋아도 학습률, 정규화, 초기화 같은 훈련 전략이 잘못되면 성능이 떨어짐  
② 출력이 0이나 1이면 기울기가 0이 되어 역전파가 끊김  
③ ReLU는 음수 입력에서 완전히 기울기가 0이 되지만,  
   Leaky ReLU는 기울기 소실을 막기 위해 작은 기울기를 둠  
④ 단순 평균 빼기보다 한 단계 더 나아가 **스케일까지 맞춰 학습 효율성을 높임**

---

# 확인문제  

---

① 드롭아웃의 문제점을 설명하시오.  
② 계단식 학습 비율 감소 방식의 단점은?  
③ 학습 비율 선정의 기본 전략은?  
④ 하이퍼파라미터를 선정하는 두 가지 방식은?

---

# 확인문제 정답 및 해설  

---

① 학습 시 실질적 출력 값이 줄어드나, 테스트 시에는 뉴런을 전부 사용하기 때문에  
   학습-추론 간 분포 차이가 생겨 성능이 저하됨  

② 변경 지점을 여러 개 선정하여 복잡하여 학습 곡선이 불안정할 수 있음  

③ 학습 초반에는 큰 학습 비율로 손실 함수 표면의 넓은 영역을 빠르게 탐색하고,  
   이후 안정적 수렴을 위해 학습 비율을 줄임  

④ **그리드 탐색**은 후보들을 격자처럼 전부 조합하는 방식,  
   **랜덤 탐색**은 무작위로 값을 선택하여 효율적으로 시간 절약

---

# 강의 정리  

---

## 오늘 공부한 내용  
요약 및 정리

### 핵심 메시지
- 좋은 모델 구조만으로는 성능 보장 X  
- 학습 전략이 안정적이고 효율적인 학습의 열쇠  

### 이번 강의에서 다룬 학습 전략
- 활성화 함수 선택  
- 가중치 초기화  
- 정규화 기법  
- 데이터 전처리  
- 하이퍼파라미터 탐색  

---

# 감사합니다 🙏  
