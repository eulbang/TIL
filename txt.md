- 학습 목표  
  - 회귀(연속값)와 분류(범주값)의 문제 정의와 출력 차이 이해  
  - 문제 유형에 맞는 오류/평가지표를 바르게 선택·해석  
  - 학습의 목적: 테스트 성능 최대화(테스트 오류 최소화)에 대한 이해  
  - 오버피팅(overfitting)의 이해  

---

- 0. 학습 시작  
  - 지도 학습: “훈련 데이터가 아니라, 처음 보는 데이터에서의 예측 성능 향상”  
    - 지도학습은 **입력 + 정답(레이블)**을 가지고 예측 규칙을 배우는 방법  
    - 이미 갖고 있는 데이터를 활용하여 학습하지만, 새로운 데이터에서의 예측을 잘 하고자 하는 데 초점  
    - 예) 고객 데이터로 “내일 이탈할 고객” 미리 알기, 기존 거래 사기로 새로운 사기 탐지  

---

- 1-1. 지도학습(supervised learning)이란?  
  - **데이터**: 입력(특성)과 정답(라벨)이 쌍으로 있는 데이터  
  - **목표**: 새 입력이 들어오면 정답을 잘 맞추는 규칙을 학습  
  - **지도학습의 종류**  
    - 회귀: 예측값이 **숫자** (가격, 점수, 온도 등)  
    - 분류: 예측값이 **범주** (스팸/정상, 질병 유/무 등)  

---

- 1-2. 지도학습 용어  
  - **특성(Feature, x)**  
    - 예측에 쓰는 설명 변수  
    - 예: 집값 예측(지역, 평수, 방수, 연식), 이메일 스팸 필터링(제목, 내용 텍스트, 송신인)
  - **라벨(Label, y)**  
    - 맞춰야 하는 정답  
    - 예: 집값, 스팸/정상 이메일  
  - **예측값(ŷ)**  
    - 모델이 내놓은 결과 (숫자 또는 범주)  
  - **오류(Error)**  
    - 예측값(ŷ)과 라벨(y)의 차이:  ŷ - y  

- 2-1. 회귀(Regression) 문제  
  - 입력으로부터 숫자를 얼마나 정확히 예측할까?  
    - Feature: 면적·방수·연식 → Label: **집값(원 단위)**  
    - Feature: 매체별 광고비(TV/라디오/온라인) → Label: **매출액**  
  - 라벨 및 예측 모델의 출력  
    - 연속적인 수치  

---

- 2-2. 회귀 오류: 평균제곱오차(MSE)  
  - **평균제곱오차(Mean Squared Error)**  
    - 각 데이터에서 정답($y_i$)과 예측값($\hat{y_i}$)의 평균 제곱 차이값  
      $$
      MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y_i})^2
      $$
  - **해석**  
    - 큰 오류를 더 크게 벌주므로, 전체 오류 수준을 한눈에 봄  
  - **참고**  
    - 데이터와 같은 단위를 쓰고 싶으면 RMSE(MSE의 제곱근)도 사용  
      $$
      RMSE = \sqrt{MSE} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y_i})^2}
      $$

- 2-3. 회귀 설명력: R² (결정계수)  
  - **결정계수**  
    - 라벨의 분산 중에서 특성으로 설명되는 비율  
    - “평균만 쓰는 단순한 예측”보다 얼마나 더 잘 맞추는지를 0~1 사이로 나타낸 값  
      $$
      R^2 = 1 - \frac{\sum_{i=1}^{n}(y_i - \hat{y_i})^2}{\sum_{i=1}^{n}(y_i - \bar{y})^2}
      \quad \text{where } \bar{y} = \text{평균값 of } y_i
      $$
  - **해석**  
    - 1에 가까울수록 설명력이 높고, 낮을수록 설명력이 낮음  
  - **질문**  
    - R²가 음수가 나올 수 있을까?  
      → 나올 수 있음. 예측값($\hat{y_i}$)들이 평균값 $\bar{y}$보다도 못한 경우에 발생

- 3-1. 분류(Classification) 문제  
  - 입력으로부터 범주는 얼마나 정확히 가려낼까?  
    - Feature: 메일 내용·보낸이 이메일주소 → Label: **스팸/정상**  
    - Feature: 종양 반경, 면적 → Label: **악성/양성**  
  - **라벨**  
    - 범주 라벨(이진/다중)  

---

- 3-2. 분류 정확도(Accuracy)  
  - **정확도**  
    - 전체 중 맞춘 비율  
      $$
      Accuracy = \frac{1}{n} \sum_{i=1}^{n} \mathbb{I}(y_i = \hat{y_i})
      \quad \text{where } \mathbb{I}(A)=1 \text{ if } A \text{ is true}
      $$
  - **정확도만 보면 발생하는 문제**  
    - 불균형 데이터(양성 1%, 음성 99%)에서는 전부 음성이라 해도 정확도가 99%로 보일 수 있음  
  - **결론**  
    - 정확도만 보지 말고 다른 지표도 함께 봐야 안전  

---

- 3-3. 혼동행렬(Confusion Matrix)  
  - **혼동행렬**  
    - 예측과 실제 값 사이의 관계를 행렬 형태로 표현  
    - TP: 실제 양성, 예측도 양성  
    - TN: 실제 음성, 예측도 음성  
    - FP: 실제는 음성인데 양성이라 함 (오탐)  
    - FN: 실제는 양성인데 음성이라 함 (누락)  

  - **정밀도(Precision)**  
    - “양성이라 판정한 것 중” 진짜 양성의 비율  
      $$
      Precision = \frac{TP}{TP + FP}
      $$
  - **재현율(Recall or Sensitivity)**  
    - “진짜 양성 가운데” 잡아낸 예측 양성 비율  
      $$
      Recall = \frac{TP}{TP + FN}
      $$
  - **F1-score**  
    - 정밀도와 재현율의 조화평균  
      $$
      F1 = 2 \times \frac{Precision \times Recall}{Precision + Recall}
      $$

- 4-1. 학습의 목적  
  - 학습의 목적은 **테스트 예측(일반화)**  
    - 학습 모델의 성능 평가는 모델이 **처음 보는 데이터(학습에 사용되지 않은 데이터)** 로 수행  
    - **일반화(generalization)**: 오류의 최소화 지향  
  - 훈련 데이터에서 성능이 아무리 좋아도, 새로운 데이터에서 성능이 떨어지면 실전엔 사용 불가  
  - 이후 차시에서 **일반화 성능 추정(검증/교차검증)** 방법 학습 예정  

---

- 4-2. 오버피팅(Overfitting)이란?  
  - **정의:** 훈련 데이터의 우연한 패턴/잡음까지 외워버려서,  
    훈련에서는 잘 맞지만 테스트에서는 성능이 나빠지는 현상  
  - **현상:**  
    - 훈련 오류: 급격히 낮음  
    - 테스트 오류: 높음 / 요동  
  - **문제점:**  
    - **표본 의존/불안정성:** 훈련 데이터의 일부 표본에 우연한 잡음이 섞이면  
      샘플 몇 개만 바뀌어도 예측이 크게 흔들림 (분산↑)  
    - **일반화 실패:** 보지 못한 데이터(테스트)에서 오차 커짐 → 실전 성능과 괴리 발생  

---

- 4-3. 오버피팅에 대한 오해  
  - 오버피팅 ≠ **분포 변화(distribution shift)** 로 인한 에러 증가  
  - **분포 변화로 인한 오류:**  
    - 훈련 데이터 분포와 테스트 데이터 분포가 달라서 발생  
    - (예: 환경·계절·센서 변화 등)  
  - 분포 변화로 인한 에러는 모델이 과적합하지 않아도 발생 가능  

---

- 4-4. 오버피팅 vs 언더피팅  
  - **오버피팅:**  
    - 모델이 너무 복잡  
    - → 잡음까지 학습 → 테스트 성능 저하  
  - **언더피팅:**  
    - 모델이 단순하거나 학습이 불충분  
    - → 중요한 패턴을 놓침 → 오류 큼  
  - **해결 실마리:**  
    - 더 많은 데이터, 테스트 데이터를 활용한 모델 선정  
    - 교차 검증 등으로 균형 잡기

- 학습 목표  
  - 훈련 오류 vs 테스트 오류의 차이를 이해하고,  
    왜 **테스트 예측(일반화)** 이 모델 학습의 목표인지 설명할 수 있다.  
  - 검증셋(hold-out), **K-겹 교차검증(K-fold Cross-Validation)** 의 개념을 학습한다.  

---

- 1. 테스트 성능 평가  
  - **훈련 오류 vs 테스트 오류**  
    - 훈련 오류: 모델을 학습시킨 **같은 데이터**에 대해 계산한 오류  
    - 테스트 오류: 학습에 사용되지 않은 **새로운 데이터**에 대한 예측 오류  
    - 보통 훈련 오류 < 테스트 오류  
      → 훈련 오류는 과소평가되는 경향이 있음 (ex. 암기 vs 응용시험)  

---

- 1-1. 훈련 오류 vs 테스트 오류 그래프 해석  
  - 파란색 선: 훈련 오류 (계속 감소)  
  - 빨간색 선: 테스트 오류 (U자형)  
  - **목표:** 테스트 오류의 U자형 곡선 바닥이 되도록 모델 복잡도 조정  

---

- 1-2. 테스트 예측 오류 계산  
  - **이상적 케이스:** 충분히 큰 별도의 테스트 데이터셋을 사용  
  - **현실적 문제:** 데이터가 한정되어 테스트 전용 세트를 확보하기 어려움  

  - **대안 – 재표본화(Resampling) 접근**  
    - 데이터를 여러 번 나누어 ‘훈련-평가’를 반복  
    - 대표적인 방법:  
      - 검증셋(hold-out)  
      - **K-겹 교차검증(K-fold Cross-Validation)**  
    - **장점:** 별도의 테스트 세트 없이 데이터를 효율적으로 활용해  
      일반화 오차를 안정적으로 추정 가능

- 2-1. 검증셋(Validation Set) 방법  
  - **검증셋(홀드아웃, hold-out) 방법**  
    - 가용 샘플을 무작위로 **훈련셋**과 **검증셋**으로 분할  
    - 훈련셋으로 모델을 학습하고, 검증셋으로 예측 후 **검증 오류** 계산  
    - 검증 오류 계산 방식  
      - 정량 예측 → **MSE(평균제곱오차)**  
      - 범주 예측 → **오분류율** 또는 **F1-score**

---

- 2-2. 검증셋 절차  
  - 데이터 순서를 무작위 **셔플(shuffle)** 후 두 부분으로 나눔  
    - 왼쪽(파랑) → 훈련셋  
    - 오른쪽(주황) → 검증셋  
  - 학습은 **훈련셋**, 성능 평가는 **검증셋**에서 수행  

---

- 2-3. 검증셋 방법 예시  
  - **예시: 자동차 데이터**
    - 목표: 선형(1차) 모델부터 고차항(다항식) 모델까지 비교  
    - 392개 데이터를 무작위로 196개 훈련셋 / 196개 검증셋 분할  
    - **좌측 패널:** 단 한 번 분할 시의 MSE 곡선  
    - **우측 패널:** 여러 번 셔플 후 분할 시 서로 다른 MSE 곡선  

---

- 2-4. 검증셋 접근의 한계  
  - 단점  
    - 훈련/검증셋에 어떤 표본이 들어가느냐에 따라 **검증 기반 테스트 오류 추정치가 가변적**  
    - 전체 데이터를 모두 사용하지 못하므로  
      - **성능이 낮게 추정**되거나 (**테스트 오류 과대추정**)  
      - 일부 데이터에만 과도하게 맞춰질 수 있음  
  - 원인  
    - 학습에 데이터의 일부만 사용하기 때문 → 데이터 활용 비효율  

- 3-1. K-겹 교차검증 (K-fold Cross-Validation)  
  - **정의:** 테스트 오류 추정의 표준적 접근 방법  
  - **활용:** 모델 선택 및 최종 모델의 테스트 오류 규모 파악  
  - **원리:**  
    - 전체 데이터를 크기 동일한 **K개 폴드(fold)** 로 무작위 분할  
    - 각 반복에서 하나의 폴드는 **검증셋**, 나머지 K−1개는 **훈련셋**  
    - 모든 폴드(k=1,…,K)에 대해 반복 후 **평균 오류**로 테스트 오류 추정  
  - **절차:**  
    1. 데이터를 무작위로 섞음(shuffle)  
    2. K개 그룹으로 분할  
    3. 각 그룹을 번갈아 **검증셋**, 나머지를 **훈련셋**으로 사용  
    4. 각 폴드의 MSE를 계산하고 평균을 내어 **테스트 오류 추정**  

---

- 3-2. K-겹 교차검증 오류 계산  
  - 폴드 집합: \( C_1, C_2, ..., C_K \), 각 폴드 크기 \( n_k \)  
  - **공식:**  
    \[
    CV(K) = \sum_{i=1}^{n} \frac{n_k}{n} MSE_k
    \]
  - 각 폴드의 MSE:  
    \[
    MSE_k = \frac{1}{n_k} \sum_{i \in C_k} (y_i - \hat{y_i})^2
    \]  
  - \( K = n \)이면 **Leave-One-Out 교차검증(LOOCV)**  

---

- 3-3. Leave-One-Out 교차검증  
  - **훈련셋:** 관측치 하나를 제외한 나머지 전체  
  - **검증셋:** 제외된 단 1개의 관측치  
  - 이 과정을 n번 반복 → 나온 n개의 MSE 평균으로 테스트 오류 추정  

---

- 3-4. K-겹 교차검증 비교  
  - **비교 대상:** Leave-One-Out vs 10-겹 교차검증  
  - 자동차 데이터 예시에서  
    - 두 방법 모두 경향과 최적 차수가 거의 동일  
  - **시사점:**  
    - 10-겹 교차검증(CV)은 테스트 성능 추정에 효율적이며  
      **LOOCV의 좋은 근사 대안**

- 학습 목표  
  - 비지도 학습의 개념과 지도학습과의 차이점을 설명한다.  
  - 클러스터링의 개념과 대표적 방법론인 **K-means** 및 **계층적 군집법**을 이해한다.  

---

- 1. 비지도 학습(Unsupervised Learning)  
  - **정의:** 레이블(정답) 없이 데이터의 구조·패턴·집단(잠재 그룹)을 찾아내는 학습  
  - **대표 과제:**  
    - 군집화(Clustering)  
    - 차원축소(PCA 등)  
    - 밀도추정·이상치 탐지  
  - **출력:** 정답 예측이 아닌 구조·요약·표현(embedding)

  - **핵심 질문**  
    - 무엇을 비슷/다름으로 볼 것인가? (거리·유사도 척도 선택)  
    - 전처리(스케일 표준화 등)는 어떻게 할 것인가?  
    - 결과 해석: 구조/요약/표현 중심  

---

- 1-2. 비지도 vs 지도 학습  
  - **지도학습:** 입력 + 라벨을 기반으로 예측 모델 학습  
    - 예시: 가격 예측, 악성 종양 예측  
  - **비지도학습:** 입력만으로 데이터 구조 학습  
    - 예시: 고객 세그먼트 구분  
  - **비지도학습 예시 – 클러스터링**  
    - 비슷한 데이터끼리 묶어 **동질 그룹(cluster)** 형성

- 2. 클러스터링(Clustering)  
  - **정의:** 데이터 안에서 하위 집단(클러스터)을 찾는 기법들의 총칭  
  - **목표:**  
    - 집단 내부는 서로 **유사**,  
    - 집단 간은 서로 **상이**하도록 데이터 분할  
  - **특징:**  
    - 유사도/상이도 정의는 도메인 맥락에 따라 달라질 수 있음  
    - 데이터의 구조와 분포 특성에 강하게 의존  

  - **예시: 마케팅 세그먼테이션**  
    - 여러 지표(가구 소득, 직업, 도심 거리 등)를 기준으로  
      **특정 광고나 상품에 더 반응할 하위 집단**을 식별  
    - 시장 세분화 작업이 곧 클러스터링  

  - **대표 알고리즘 2가지**  
    - **K-평균(K-means):** K(클러스터 수)를 사전에 지정  
    - **계층적 군집(Hierarchical):** K를 사전에 정하지 않음  

---

- 3-1. K-means 클러스터링  
  - **결과 예시:**  
    - K = 2, 3, 4 등으로 설정한 K-means 결과 비교 (색상 = 각 클러스터)  
    - 색상은 의미가 없으며, 서로 다른 색은 서로 다른 클러스터를 의미  

  - **수학적 표기:**  
    - 관측치 인덱스 집합 \( C_1, \dots, C_K \)  
    - 모든 관측치는 정확히 하나의 군집에 속함 (비중첩 분할)  
    - 좋은 군집: **클러스터 내부 변동(Within-Cluster Variation)** 이 작음  

  - **핵심 아이디어:**  
    - 목표: **클러스터 내부 변동의 합이 최소**가 되도록 분할  
    - 내부 거리(혹은 흩어짐)가 가장 작은 구성을 찾음  

---

- 3-2. K-means 알고리즘  
  - **절차:**  
    1. 초기화 — 관측치를 무작위로 1~K개의 군집에 배정  
    2. 반복 (수렴할 때까지):  
       - (2a) 각 군집의 **중심(centroid)** 계산  
       - (2b) 각 관측치를 **가장 가까운 중심**의 클러스터로 재배정  
  - **특징:**  
    - 매 반복마다 목표함수(군집 내 평균 거리)를 감소시킴  
    - 단, 전역 최솟값을 보장하지 않음 → **초기값에 따라 지역해(local minimum)** 가능  
    - → **여러 번 시도**하여 안정적인 결과 확인 권장  

  - **흐름 요약:**  
    ```
    1. 무작위 초기화
    ↓
    2a. 중심 계산
    ↓
    2b. 클러스터 재배정
    ↳ 반복
    ```

  - **초기값의 영향:**  
    - 서로 다른 초기값에 따라 결과 분할과 목표값이 달라질 수 있음  
    - 따라서 여러 번 시도하여 최적의 분할을 선택하는 것이 중요

- 4-1. 계층적 군집(Hierarchical Clustering)  
  - **K-means vs 계층적 군집**  
    - K-means: K(클러스터 수)를 **미리 지정**해야 함  
    - 계층적 군집: K를 **사전에 고정하지 않고**, 전체 구조를 **덴드로그램(dendrogram)** 으로 시각화  
  - **유형:**  
    - 이번 학습에서는 **상향식(Agglomerative)** 접근을 다룸 — 개별 데이터에서 시작 → 병합  

---

- 계층적 군집 결과 해석  
  - 덴드로그램의 **수평선 높이(거리)** 를 기준으로 **K개의 군집**을 형성  

---

- 4-2. 계층적 군집 알고리즘 (상향식)  
  - **절차:**  
    1. 각 관측치를 하나의 클러스터로 시작  
    2. 모든 쌍의 클러스터 간 **유사도(또는 거리)** 계산  
    3. 가장 유사한 두 클러스터를 병합  
    4. 새로 형성된 클러스터와 나머지 클러스터 간의 **새 거리**를 다시 계산  
    5. 위 과정을 한 개의 클러스터가 될 때까지 반복  

---

- 4-3. 단계별 진행  
  - **핵심 개념:**  
    - 데이터가 점차 큰 클러스터로 **병합**되는 과정  
    - 매 단계마다 클러스터 간 병합이 이루어짐  
    - 최종적으로 모든 데이터가 단일 클러스터가 될 때까지 진행  
  - **계산량:**  
    - 각 단계에서 모든 쌍의 클러스터 거리를 계산해야 함  
    - 데이터가 많을수록 K-means보다 **계산량이 많음**  

---

- 4-4. 링크(Link)의 유형  
  - **Single (최소 거리):**  
    두 클러스터 내 데이터 간 **쌍별 거리 중 최소값**을 군집 간 거리로 사용  
  - **Complete (최대 거리):**  
    두 클러스터 내 데이터 간 **쌍별 거리 중 최대값**을 군집 간 거리로 사용  
  - **Average (평균 거리):**  
    두 클러스터 내 데이터 간 **쌍별 거리의 평균값**을 군집 간 거리로 사용  

---

- 4-5. 링크 유형에 따른 군집 결과  
  - **링크 선택에 따라 결과가 달라질 수 있음**  
    - 같은 데이터라도 링크 유형(Single, Complete, Average 등)에 따라  
      덴드로그램과 클러스터링 결과가 다름  
  - **권장사항:**  
    - 하나의 링크만 사용하지 말고 **여러 링크 유형을 비교**하여 적절한 결과 선택

---

- 5. 클러스터링 시 주의점  

  **클러스터링 체크리스트**

  - **스케일링(Scaling)**  
    - 표준화(평균 0, 표준편차 1로 변환)가 필요한가?  
      → **Yes**, 변수 단위 차이가 크면 결과에 큰 영향  

  - **클러스터 개수 결정**  
    - 몇 개의 클러스터가 적합한지는  
      K-means, 계층적 군집 모두에서 **명확한 정답이 없음**  
      → 여러 K값 시도 후 비교 권장  

  - **단일 시도보다 반복 시도 권장**  
    - 초기값이나 데이터 분할에 따라 결과가 달라질 수 있으므로  
      여러 번 실행하여 **안정적인 분할** 확인 필요
