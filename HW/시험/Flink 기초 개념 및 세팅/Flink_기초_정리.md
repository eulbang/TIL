

ğŸ“Œ Flink ê¸°ì´ˆ ê°œë… ë° ì„¸íŒ… ì‹¤ìŠµ/ê³¼ì œ ì •ë¦¬
---
- [WS 7-1: PyFlink ì„¤ì¹˜ ë° í…ŒìŠ¤íŠ¸](#ws-7-1-pyflink-ì„¤ì¹˜-ë°-í…ŒìŠ¤íŠ¸)
- [WS 7-2: ê¸°ë³¸ ìŠ¤íŠ¸ë¦¼ ìƒì„±](#ws-7-2-ê¸°ë³¸-ìŠ¤íŠ¸ë¦¼-ìƒì„±)
- [WS 7-3: CSV â†’ WordCount](#ws-7-3-csv--wordcount)
- [WS 7-4: ì‹¤ì‹œê°„ WordCount](#ws-7-4-ì‹¤ì‹œê°„-wordcount)
- [WS 7-5: ìŠ¤íŠ¸ë¦¼ ê²°í•©Â·FileSink](#ws-7-5-ìŠ¤íŠ¸ë¦¼-ê²°í•©filesink)
- [HW 7-2: ë‰´ìŠ¤ WordCount](#hw-7-2-ë‰´ìŠ¤-wordcount)
- [HW 7-4: ê±°ë˜ ìœ í˜•ë³„ ì§‘ê³„](#hw-7-4-ê±°ë˜-ìœ í˜•ë³„-ì§‘ê³„)

## WS 7-1: PyFlink ì„¤ì¹˜ ë° í…ŒìŠ¤íŠ¸
- ëª©í‘œ: WSLì—ì„œ PyFlink 1.19.3 ì„¤ì¹˜ í›„ ê°„ë‹¨í•œ ìŠ¤íŠ¸ë¦¼ ì‹¤í–‰ í™•ì¸.
- í•µì‹¬ ë‹¨ê³„: ì‹¤í–‰ í™˜ê²½ ìƒì„± â†’ ë³‘ë ¬ì„± 2 ì„¤ì • â†’ ì»¬ë ‰ì…˜ ìŠ¤íŠ¸ë¦¼ ìƒì„±/ì¶œë ¥ â†’ `env.execute`.
- ì •ë‹µ ì½”ë“œ: `data_engineering1_ws_7_1/skeleton/skeleton.py`
```python
from pyflink.datastream import StreamExecutionEnvironment

def main():
    env = StreamExecutionEnvironment.get_execution_environment()
    env.set_parallelism(2)
    data_stream = env.from_collection(["Hello", "Flink", "World"])
    data_stream.print()
    env.execute("Flink Installation Test")

if __name__ == "__main__":
    main()
```

## WS 7-2: ê¸°ë³¸ ìŠ¤íŠ¸ë¦¼ ìƒì„±
- ëª©í‘œ: PyFlink ì‹¤í–‰ í™˜ê²½ êµ¬ì„± í›„ ë¦¬ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ë³€í™˜í•´ ì¶œë ¥.
- ì •ë‹µ ì½”ë“œ: `data_engineering1_ws_7_2/skeleton/skeleton.py`
```python
from pyflink.datastream import StreamExecutionEnvironment

def main():
    env = StreamExecutionEnvironment.get_execution_environment()
    data_stream = env.from_collection(["Hello", "Flink", "World"])
    data_stream.print()
    env.execute("Flink Installation Test")

if __name__ == "__main__":
    main()
```

## WS 7-3: CSV â†’ WordCount
- ëª©í‘œ: CSV(news_text) ë¡œë“œ â†’ ê²°ì¸¡ ì œê±° â†’ ìŠ¤íŠ¸ë¦¼ ë³€í™˜ â†’ WordCount.
- ì •ë‹µ ì½”ë“œ: `data_engineering1_ws_7_3/skeleton/skeleton.py`
```python
import pandas as pd
from pyflink.datastream import StreamExecutionEnvironment
from pyflink.common.typeinfo import Types

def main():
    env = StreamExecutionEnvironment.get_execution_environment()
    env.set_parallelism(2)

    df = pd.read_csv("../data/data.csv")
    news_texts = df["news_text"].dropna().tolist()
    text_stream = env.from_collection(news_texts, type_info=Types.STRING())

    word_count = (text_stream
                  .map(lambda text: [(word.lower(), 1) for word in text.split()],
                       output_type=Types.LIST(Types.TUPLE([Types.STRING(), Types.INT()])))
                  .flat_map(lambda words: words,
                            output_type=Types.TUPLE([Types.STRING(), Types.INT()]))
                  .key_by(lambda x: x[0])
                  .reduce(lambda a, b: (a[0], a[1] + b[1])))

    word_count.print()
    env.execute("Finance News WordCount")

if __name__ == "__main__":
    main()
```

## WS 7-4: ì‹¤ì‹œê°„ WordCount
- ëª©í‘œ: CSV(news_text) â†’ ìŠ¤íŠ¸ë¦¼ â†’ `flat_map` + `reduce`ë¡œ ì‹¤ì‹œê°„ ë‹¨ì–´ ì§‘ê³„.
- ì •ë‹µ ì½”ë“œ: `data_engineering1_ws_7_4/skeleton/skeleton.py`
```python
import pandas as pd
from pyflink.datastream import StreamExecutionEnvironment
from pyflink.common.typeinfo import Types

def main():
    env = StreamExecutionEnvironment.get_execution_environment()
    env.set_parallelism(2)

    df = pd.read_csv("../data/data.csv")
    news_texts = df["news_text"].dropna().tolist()
    text_stream = env.from_collection(news_texts, type_info=Types.STRING())

    word_count = (text_stream
                  .flat_map(lambda text: [(word.lower(), 1) for word in text.split()],
                            output_type=Types.TUPLE([Types.STRING(), Types.INT()]))
                  .key_by(lambda x: x[0])
                  .reduce(lambda a, b: (a[0], a[1] + b[1])))

    word_count.print()
    env.execute("Streaming Finance News WordCount")

if __name__ == "__main__":
    main()
```

## WS 7-5: ìŠ¤íŠ¸ë¦¼ ê²°í•©Â·FileSink
- ëª©í‘œ: ìˆ˜ë™ ë°ì´í„° + CSV(transaction_id, amount) ìŠ¤íŠ¸ë¦¼ì„ union í›„ ê¸ˆì•¡ 1.2ë°° ë³€í™˜, ì¶œë ¥ ë° íŒŒì¼ ì €ì¥.
- ì •ë‹µ ì½”ë“œ: `data_engineering1_ws_7_5/skeleton/skeleton.py`
```python
import pandas as pd
from pyflink.datastream import StreamExecutionEnvironment
from pyflink.datastream.connectors import FileSink
from pyflink.common.serialization import Encoder
from pyflink.common.typeinfo import Types

def main():
    env = StreamExecutionEnvironment.get_execution_environment()
    env.set_parallelism(2)

    manual_data = [("Manual1", 1000.0), ("Manual2", 2000.0)]
    manual_stream = env.from_collection(manual_data,
                                        type_info=Types.TUPLE([Types.STRING(), Types.FLOAT()]))

    df = pd.read_csv("../data/data.csv")
    file_data = df[["transaction_id", "amount"]].dropna().values.tolist()
    file_stream = env.from_collection(file_data,
                                      type_info=Types.TUPLE([Types.STRING(), Types.FLOAT()]))

    combined_stream = manual_stream.union(file_stream)
    processed_stream = combined_stream.map(lambda x: (x[0], x[1] * 1.2))

    string_stream = processed_stream.map(lambda x: f\"{x[0]},{x[1]}\", output_type=Types.STRING())
    string_stream.print()

    file_sink = FileSink.for_row_format(
        "./output/transactions_result",
        Encoder.simple_string_encoder()
    ).build()

    string_stream.sink_to(file_sink)
    env.execute("Custom Source and Sink Example")

if __name__ == "__main__":
    main()
```

## HW 7-2: ë‰´ìŠ¤ WordCount
- ëª©í‘œ: ì‹¤í–‰ í™˜ê²½/ë³‘ë ¬ì„± ì„¤ì • í›„ news_text ì»¬ëŸ¼ìœ¼ë¡œ WordCount ìˆ˜í–‰.
- ì •ë‹µ ì½”ë“œ: `data_engineering1_hw_7_2/skeleton/skeleton.py`
```python
import pandas as pd
from pyflink.datastream import StreamExecutionEnvironment
from pyflink.common.typeinfo import Types

def main():
    env = StreamExecutionEnvironment.get_execution_environment()
    env.set_parallelism(2)

    df = pd.read_csv("../data/data.csv")
    news_texts = df["news_text"].dropna().tolist()
    text_stream = env.from_collection(news_texts, type_info=Types.STRING())

    word_count = (text_stream
                  .map(lambda text: [(word.lower(), 1) for word in text.split()],
                       output_type=Types.LIST(Types.TUPLE([Types.STRING(), Types.INT()])))
                  .flat_map(lambda words: words,
                            output_type=Types.TUPLE([Types.STRING(), Types.INT()]))
                  .key_by(lambda x: x[0])
                  .reduce(lambda a, b: (a[0], a[1] + b[1])))

    word_count.print()
    env.execute("Finance News WordCount")

if __name__ == "__main__":
    main()
```

## HW 7-4: ê±°ë˜ ìœ í˜•ë³„ ì§‘ê³„
- ëª©í‘œ: ê±°ë˜ ë°ì´í„°(transaction_type, amount)ë¥¼ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ë³€í™˜í•´ ìœ í˜•ë³„ ê¸ˆì•¡ í•©ê³„ ê³„ì‚°.
- ì •ë‹µ ì½”ë“œ: `data_engineering1_hw_7_4/skeleton/skeleton.py`
```python
import pandas as pd
from pyflink.datastream import StreamExecutionEnvironment
from pyflink.common.typeinfo import Types

def main():
    env = StreamExecutionEnvironment.get_execution_environment()
    env.set_parallelism(2)

    df = pd.read_csv("../data/data.csv")
    transactions = df[["transaction_type", "amount"]].dropna().values.tolist()
    transaction_stream = env.from_collection(transactions,
                                             type_info=Types.TUPLE([Types.STRING(), Types.FLOAT()]))

    transaction_total = (transaction_stream
                         .key_by(lambda x: x[0])
                         .reduce(lambda a, b: (a[0], a[1] + b[1])))

    transaction_total.print()
    env.execute("Transaction Type Aggregation")

if __name__ == "__main__":
    main()
```
