{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lY2ef3IwSUbU"
      },
      "source": [
        "# baseline v3\n",
        "\n",
        "이 베이스라인 코드는 `사전학습 모델 로드`, `배치 학습`, `파인튜닝`, `양자화`, `PEFT` 등이 적용된 버전입니다.\n",
        "\n",
        "Colab의 GPU 환경에서 개발되었습니다.\n",
        "- 런타임 - 런타임 유형 변경 - GPU로 변경(T4 GPU 등)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HBjYvBZSzqr"
      },
      "source": [
        "# 환경 준비\n",
        "\n",
        "개발 환경에 필요한 라이브러리 버전을 고정하고 최신 버전으로 라이브러리를 업데이트합니다.\n",
        "\n",
        "- 아래 셀 실행\n",
        "- 실행 완료 후 런타임 - 세션 다시 시작"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGS9ISsxSqUt",
        "outputId": "6ba7817e-c961-4f45-ab86-2a7a7f91f0cd"
      },
      "outputs": [],
      "source": [
        "# !pip -q install \"transformers>=4.44.2\" \"accelerate>=0.34.2\" \"peft>=0.13.2\" \"bitsandbytes>=0.43.1\" datasets pillow pandas torch torchvision --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0wuwJLPTJpQ"
      },
      "source": [
        "# 데이터 준비\n",
        "\n",
        "개발에 필요한 데이터를 준비합니다.\n",
        "\n",
        "- train.csv, train 폴더\n",
        "- test.csv, test 폴더\n",
        "- sample_submission.csv\n",
        "\n",
        "본 베이스라인은 colab에서 구글 드라이브를 마운트하여 사용합니다.\n",
        "\n",
        "데이터를 압축 해제하는데 몇 분 정도의 시간이 소요됩니다.\n",
        "\n",
        "#### 실습 참고 내용\n",
        "\n",
        "    챕터 2-2 합성 데이터 실습\n",
        "    - 구글 드라이브 마운트 : drive()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXxjjvUpTLMA",
        "outputId": "ed4d5a6c-5e30-4010-b74e-91d8f8f0850b"
      },
      "outputs": [],
      "source": [
        "# # 구글드라이브 마운트\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nW4YNdl0Tn70",
        "outputId": "c5918de3-34b5-4907-b745-c9086a927563"
      },
      "outputs": [],
      "source": [
        "# # 압축 해제\n",
        "# !unzip \"/content/drive/My Drive/250918/data.zip\" -d \"/content/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WO2OCFiTqDv"
      },
      "source": [
        "# 라이브러리, 데이터, 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QXMeMgFT5MT",
        "outputId": "6c553fdf-ae73-4ade-bfa3-7d96292d095d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/team138/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/home/team138/venv/lib/python3.10/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os, re, math, random\n",
        "import pandas as pd\n",
        "cache_root = \"/home/team138/.cache/huggingface\"\n",
        "os.environ[\"TMPDIR\"] = cache_root\n",
        "os.environ[\"HF_HOME\"] = cache_root\n",
        "os.environ[\"HUGGINGFACE_HUB_CACHE\"] = cache_root\n",
        "os.environ[\"HF_MODULES_CACHE\"] = os.path.join(cache_root, \"modules\")\n",
        "os.environ[\"TRANSFORMERS_CACHE\"] = cache_root\n",
        "os.environ[\"HF_DATASETS_CACHE\"] = cache_root\n",
        "os.makedirs(cache_root, exist_ok=True)\n",
        "os.makedirs(os.environ[\"HF_MODULES_CACHE\"], exist_ok=True)\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from dataclasses import dataclass\n",
        "import torch\n",
        "from typing import Dict, List, Any\n",
        "from transformers import (\n",
        "    AutoModelForVision2Seq,\n",
        "    AutoProcessor,\n",
        "    BitsAndBytesConfig,\n",
        "    get_linear_schedule_with_warmup\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "from tqdm import tqdm\n",
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        ")\n",
        "\n",
        "# 이미지 로드 시 픽셀 제한 해제\n",
        "Image.MAX_IMAGE_PIXELS = None\n",
        "\n",
        "# 디바이스 GPU 우선 사용 설정\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# 사전 학습 모델 정의\n",
        "MODEL_ID = \"OpenGVLab/InternVL2-8B\"\n",
        "IMAGE_SIZE = 384\n",
        "MAX_NEW_TOKENS = 8\n",
        "SEED = 42\n",
        "random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# 데이터셋 로드\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df  = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# 학습데이터 200개만 추출\n",
        "train_df = train_df.sample(n=200, random_state=SEED).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'transformers_modules.OpenGVLab.InternVL2_hyphen_8B.6fb9ad6924f69424e57fab2ab061d707688f0296.tokenization_internlm2.InternLM2Tokenizer'>\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoProcessor, AutoModelForCausalLM\n",
        "\n",
        "model_id = \"OpenGVLab/InternVL2-8B\"\n",
        "hf_token = \"\"  # 공개 모델이면 None 또는 인자 제거\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, token=hf_token,\n",
        "                                          cache_dir=cache_root, trust_remote_code=True)\n",
        "processor = AutoProcessor.from_pretrained(model_id, token=hf_token,\n",
        "                                          cache_dir=cache_root, trust_remote_code=True)\n",
        "\n",
        "print(type(processor))\n",
        "print(getattr(processor, \"image_token\", None))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLdJb59EULQv"
      },
      "source": [
        "# 모델, Processor\n",
        "\n",
        "7.5GB 정도의 모델 다운로드가 진행됩니다. 10~20분 정도가 소요됩니다.\n",
        "\n",
        "#### 실습 참고 내용\n",
        "\n",
        "    챕터 5-1 PEFT(파라미터 효율적 튜닝)\n",
        "    - LoRA 구현 : LoraConfig()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253,
          "referenced_widgets": [
            "6dafd6a2188d4e448ec077630a9d7d20",
            "4767df1e8b7e43ee8b466dfe087b1ef4",
            "5d4ba90bb49c4f2c8ae8c71032e061dd",
            "c681a9babaac4fc4b01ed90aaa8367ae",
            "51666bc88ac943f7b8aaf46bc9c5cd7a",
            "e3dc16bc47a346029d42c78c27f26f77",
            "c60f821626fb4b53beeb0499ac113113",
            "1a96441f9d5d43aab8466a9bf13c4cdd",
            "94396c8893eb46fdac64d7ea5a02c9a2",
            "a13bc776ff074560a704aa9d601985d2",
            "2900d4c8a80e43da80988161daa92df3"
          ]
        },
        "id": "NbinSBK_Ubgo",
        "outputId": "d61368e2-30c1-4563-f4a2-60b41329c86e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "InternLM2ForCausalLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
            "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
            "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
            "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Flash attention is not available, using eager attention instead.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading checkpoint shards: 100%|██████████| 4/4 [00:20<00:00,  5.01s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== LoRA 적용 가능 모듈 후보 ===\n",
            "vision_model.encoder.layers.0.attn.proj_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
            "vision_model.encoder.layers.0.attn.proj <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.0.mlp.fc1 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.0.mlp.fc2 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.1.attn.proj_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
            "vision_model.encoder.layers.1.attn.proj <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.1.mlp.fc1 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.1.mlp.fc2 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.2.attn.proj_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
            "vision_model.encoder.layers.2.attn.proj <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.2.mlp.fc1 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.2.mlp.fc2 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.3.attn.proj_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
            "vision_model.encoder.layers.3.attn.proj <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.3.mlp.fc1 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.3.mlp.fc2 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.4.attn.proj_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
            "vision_model.encoder.layers.4.attn.proj <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.4.mlp.fc1 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.4.mlp.fc2 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.5.attn.proj_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
            "vision_model.encoder.layers.5.attn.proj <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.5.mlp.fc1 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.5.mlp.fc2 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.6.attn.proj_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
            "vision_model.encoder.layers.6.attn.proj <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.6.mlp.fc1 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.6.mlp.fc2 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.7.attn.proj_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
            "vision_model.encoder.layers.7.attn.proj <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.7.mlp.fc1 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.7.mlp.fc2 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.8.attn.proj_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
            "vision_model.encoder.layers.8.attn.proj <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.8.mlp.fc1 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.8.mlp.fc2 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.9.attn.proj_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
            "vision_model.encoder.layers.9.attn.proj <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.9.mlp.fc1 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.9.mlp.fc2 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.10.attn.proj_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
            "vision_model.encoder.layers.10.attn.proj <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.10.mlp.fc1 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.10.mlp.fc2 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.11.attn.proj_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
            "vision_model.encoder.layers.11.attn.proj <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.11.mlp.fc1 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.11.mlp.fc2 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.12.attn.proj_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
            "vision_model.encoder.layers.12.attn.proj <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.12.mlp.fc1 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.12.mlp.fc2 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.13.attn.proj_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
            "vision_model.encoder.layers.13.attn.proj <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.13.mlp.fc1 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.13.mlp.fc2 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.14.attn.proj_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
            "vision_model.encoder.layers.14.attn.proj <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.14.mlp.fc1 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.14.mlp.fc2 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.15.attn.proj_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
            "vision_model.encoder.layers.15.attn.proj <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.15.mlp.fc1 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.15.mlp.fc2 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.16.attn.proj_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
            "vision_model.encoder.layers.16.attn.proj <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.16.mlp.fc1 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.16.mlp.fc2 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.17.attn.proj_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
            "vision_model.encoder.layers.17.attn.proj <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.17.mlp.fc1 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.17.mlp.fc2 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.18.attn.proj_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
            "vision_model.encoder.layers.18.attn.proj <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.18.mlp.fc1 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.18.mlp.fc2 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.19.attn.proj_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
            "vision_model.encoder.layers.19.attn.proj <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.19.mlp.fc1 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.19.mlp.fc2 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.20.attn.proj_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
            "vision_model.encoder.layers.20.attn.proj <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.20.mlp.fc1 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.20.mlp.fc2 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.21.attn.proj_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
            "vision_model.encoder.layers.21.attn.proj <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.21.mlp.fc1 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.21.mlp.fc2 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.22.attn.proj_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
            "vision_model.encoder.layers.22.attn.proj <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.22.mlp.fc1 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.22.mlp.fc2 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.23.attn.proj_drop <class 'torch.nn.modules.dropout.Dropout'>\n",
            "vision_model.encoder.layers.23.attn.proj <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.23.mlp.fc1 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "vision_model.encoder.layers.23.mlp.fc2 <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "trainable params: 2,359,296 || all params: 8,077,724,672 || trainable%: 0.0292\n"
          ]
        }
      ],
      "source": [
        "# 양자화\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        ")\n",
        "\n",
        "# 프로세서\n",
        "processor = AutoProcessor.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    min_pixels=IMAGE_SIZE*IMAGE_SIZE,\n",
        "    max_pixels=IMAGE_SIZE*IMAGE_SIZE,\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "\n",
        "# 사전학습 모델\n",
        "from transformers import AutoModelForCausalLM\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "\n",
        "# 양자화 모델로 로드\n",
        "base_model = prepare_model_for_kbit_training(base_model)\n",
        "base_model.gradient_checkpointing_enable()\n",
        "\n",
        "cfg = base_model.config\n",
        "task_type = \"CAUSAL_LM\"\n",
        "\n",
        "# LoRA 적용 후보 모듈 확인\n",
        "print(\"=== LoRA 적용 가능 모듈 후보 ===\")\n",
        "for n, m in base_model.named_modules():\n",
        "    if any(k in n for k in [\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"proj\",\"gate\",\"up\",\"down\",\"fc\",\"linear\"]):\n",
        "        print(n, type(m))\n",
        "\n",
        "# LoRA 설정\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    target_modules=[\"attn.proj\", \"mlp.fc1\", \"mlp.fc2\"],  # 실제 모델 모듈 이름\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "# PEFT 모델 생성\n",
        "model = get_peft_model(base_model, lora_config)\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvJAhuBvUnRe"
      },
      "source": [
        "# 프롬프트 템플릿\n",
        "\n",
        "#### 실습 참고 내용\n",
        "\n",
        "    챕터 5-1 PEFT(파라미터 효율적 튜닝)\n",
        "    - 프롬프트 템플릿 : convert_to_chatml(), formatting_prompts_func()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sg8oEjDdUnX4"
      },
      "outputs": [],
      "source": [
        "# 모델 지시사항\n",
        "SYSTEM_INSTRUCT = (\n",
        "    \"You are a helpful visual question answering assistant. \"\n",
        "    \"Answer using exactly one letter among a, b, c, or d. No explanation.\"\n",
        ")\n",
        "\n",
        "# 프롬프트\n",
        "def build_mc_prompt(question, a, b, c, d):\n",
        "    return (\n",
        "        f\"{question}\\n\"\n",
        "        f\"(a) {a}\\n(b) {b}\\n(c) {c}\\n(d) {d}\\n\\n\"\n",
        "        \"정답을 반드시 a, b, c, d 중 하나의 소문자 한 글자로만 출력하세요.\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmmqKcVlUsRy"
      },
      "source": [
        "# Custom Dataset, Collator\n",
        "\n",
        "#### 실습 참고 내용\n",
        "\n",
        "    챕터 1-2 MLP 구현\n",
        "    - TensorDataset()\n",
        "\n",
        "    챕터 5-2 데이터 생성 및 파인튜닝 (향후 학습 분량)\n",
        "    - IntentDataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "IBIGNbxuUtbP"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from typing import Any\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "# 커스텀 데이터셋\n",
        "class VQAMCDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, train: bool = True):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.train = train\n",
        "\n",
        "        specials = tokenizer.additional_special_tokens or []\n",
        "        self.image_placeholder = \"<image>\"\n",
        "        for tok in specials:\n",
        "            if tok.lower().startswith(\"<img\"):\n",
        "                self.image_placeholder = tok\n",
        "                break\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        row = self.df.iloc[i]\n",
        "        image = Image.open(row[\"path\"]).convert(\"RGB\")\n",
        "        prompt = build_mc_prompt(row[\"question\"], row[\"a\"], row[\"b\"], row[\"c\"], row[\"d\"])\n",
        "\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": SYSTEM_INSTRUCT},\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"image\", \"image\": image},\n",
        "                    {\"type\": \"text\", \"text\": prompt},\n",
        "                ],\n",
        "            },\n",
        "        ]\n",
        "        if self.train:\n",
        "            gold = str(row[\"answer\"]).strip().lower()\n",
        "            messages.append({\"role\": \"assistant\", \"content\": gold})\n",
        "\n",
        "        return {\"messages\": messages, \"image\": image}\n",
        "\n",
        "\n",
        "# 데이터 콜레이터\n",
        "@dataclass\n",
        "class DataCollator:\n",
        "    processor: Any\n",
        "    train: bool = True\n",
        "    add_generation_prompt: bool = False\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        texts, images = [], []\n",
        "        for sample in batch:\n",
        "            flat_messages = []\n",
        "            image_for_sample = None\n",
        "\n",
        "            for message in sample[\"messages\"]:\n",
        "                content = message[\"content\"]\n",
        "                if isinstance(content, list):\n",
        "                    pieces = []\n",
        "                    for item in content:\n",
        "                        if item.get(\"type\") == \"text\":\n",
        "                            pieces.append(item[\"text\"])\n",
        "                        elif item.get(\"type\") == \"image\":\n",
        "                            image_for_sample = item[\"image\"]\n",
        "                            pieces.append(\"<image>\")\n",
        "                    flat_messages.append(\n",
        "                        {\"role\": message[\"role\"], \"content\": \"\\n\".join(pieces)}\n",
        "                    )\n",
        "                else:\n",
        "                    flat_messages.append(message)\n",
        "\n",
        "            if image_for_sample is None:\n",
        "                raise ValueError(\"이미지가 포함된 turn이 없습니다.\")\n",
        "\n",
        "            text = self.processor.apply_chat_template(\n",
        "                flat_messages,\n",
        "                tokenize=False,\n",
        "                add_generation_prompt=self.add_generation_prompt,\n",
        "            )\n",
        "            texts.append(text)\n",
        "            images.append(image_for_sample)\n",
        "\n",
        "        encoded = self.processor(\n",
        "            text=texts,\n",
        "            images=images,\n",
        "            padding=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        encoded.pop(\"inputs_embeds\", None)\n",
        "        if self.train:\n",
        "            encoded[\"labels\"] = encoded[\"input_ids\"].clone()\n",
        "        return encoded\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e71vSvpaU4Xt"
      },
      "source": [
        "# DataLoader\n",
        "\n",
        "#### 실습 참고 내용\n",
        "\n",
        "    챕터 3-1 Transfer Learning 기반의 CNN 모델 학습\n",
        "    - 데이터로더 정의 : DataLoader()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "jwftyGCMU4jy"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 검증용 데이터 분리\n",
        "split = int(len(train_df)*0.9)\n",
        "train_subset, valid_subset = train_test_split(train_df, test_size=0.1, random_state=SEED, stratify=train_df[\"answer\"])\n",
        "\n",
        "# VQAMCDataset 형태로 변환\n",
        "train_ds = VQAMCDataset(train_subset, tokenizer, train=True)\n",
        "valid_ds = VQAMCDataset(valid_subset, tokenizer, train=False)\n",
        "\n",
        "# 데이터로더\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=1,\n",
        "    shuffle=True,\n",
        "    collate_fn=DataCollator(processor, train=True, add_generation_prompt=False),\n",
        "    num_workers=0,\n",
        ")\n",
        "valid_loader = DataLoader(\n",
        "    valid_ds,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    collate_fn=DataCollator(processor, train=False, add_generation_prompt=False),\n",
        "    num_workers=0,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6trj7t9U-hv"
      },
      "source": [
        "# fine-tuning\n",
        "\n",
        "- 200개만 학습 : 10~20분 소요\n",
        "\n",
        "#### 실습 참고 내용\n",
        "\n",
        "    챕터 1-2 MLP 구현\n",
        "    - 모델 정의 : SimpleMLP(), SequentialMLP()\n",
        "\n",
        "    챕터 3-1 Transfer Learning 기반의 CNN 모델 학습\n",
        "    - 학습 루프 : 문제 6: 모델 학습을 위한 반복문\n",
        "    - 추론 : with torch.no_grad(), model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228,
          "referenced_widgets": [
            "840e1478cf0f41e9907110685c5b306a",
            "7684d714a6ea421eb3acbe8a4ad41379",
            "ff9e6154da0e4a06a8f31563ae43bbef",
            "b664fb63691a4a7680a2cbb5c20b08b9",
            "6195d11a117141fabfb5e9774ef81d3c",
            "26fc51d519a34e148ac30ea2984ce2f9",
            "403bef8878f147deb789233e0bdbdafb",
            "8a6f1e76a2b04e4581ccb0247bae372a",
            "1302a6526a844fe9b7bdad7d422449a7",
            "7d74fa2a26174f83a064c7f4f37d2a0b",
            "01fd5c7afa1448be9eced088b534094d",
            "9752fdd498724b61ba90dbd5e8e09c1d",
            "8534de244cab4c74aeae82c05ac6132e",
            "9bf9592ce2134d409e1748e905b3dd62",
            "f8f66e57dbdf4147aebb05df460f87f1",
            "1e05d94757014640b1f0a4ba7e13cd25",
            "e4775ec0fb8643daa4dcaede2b20c164",
            "1716f42191b441939e4bc3b6c771fa63",
            "7b722009deaf463eaf6a6f1a199d0544",
            "baaed15657a94169abe754873570ae8e",
            "af68f248e2804569bae5ab7d8ede79e8",
            "fdd9d824e75b4f478a6c0f3b3cd4e8ab"
          ]
        },
        "id": "j3E33VlLU-ps",
        "outputId": "5833b727-1a9e-4ba7-e092-2651d28df5c2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_8342/215713023.py:18: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=grad_scaler_enabled)\n",
            "Epoch 1 [train]:   0%|          | 0/180 [00:00<?, ?batch/s]Keyword arguments {'images': [<PIL.Image.Image image mode=RGB size=720x540 at 0x773130754340>]} not recognized.\n",
            "Epoch 1 [train]:   0%|          | 0/180 [00:00<?, ?batch/s]\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "pixel_values missing from batch; check DataCollator output.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[24], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m batch\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs_embeds\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpixel_values\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpixel_values missing from batch; check DataCollator output.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m forward_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     34\u001b[0m     k: batch[k]\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpixel_values\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposition_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_flags\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m batch\n\u001b[1;32m     37\u001b[0m }\n\u001b[1;32m     38\u001b[0m forward_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[0;31mValueError\u001b[0m: pixel_values missing from batch; check DataCollator output."
          ]
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "EPOCHS = 1\n",
        "GRAD_ACCUM = 4\n",
        "grad_scaler_enabled = torch.cuda.is_available()\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
        "updates_per_epoch = math.ceil(len(train_loader) / GRAD_ACCUM)\n",
        "total_training_steps = EPOCHS * updates_per_epoch\n",
        "warmup_steps = int(total_training_steps * 0.03)\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=warmup_steps,\n",
        "    num_training_steps=total_training_steps,\n",
        ")\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=grad_scaler_enabled)\n",
        "\n",
        "global_step = 0\n",
        "for epoch in range(EPOCHS):\n",
        "    running = 0.0\n",
        "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1} [train]\", unit=\"batch\")\n",
        "    last_step = 0\n",
        "\n",
        "    for step, batch in enumerate(progress_bar, start=1):\n",
        "        batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n",
        "        batch.pop(\"inputs_embeds\", None)\n",
        "\n",
        "        if \"pixel_values\" not in batch:\n",
        "            raise ValueError(\"pixel_values missing from batch; check DataCollator output.\")\n",
        "\n",
        "        forward_inputs = {\n",
        "            k: batch[k]\n",
        "            for k in (\"pixel_values\", \"input_ids\", \"attention_mask\", \"position_ids\", \"image_flags\", \"labels\")\n",
        "            if k in batch\n",
        "        }\n",
        "        forward_inputs[\"return_dict\"] = True\n",
        "\n",
        "        with torch.cuda.amp.autocast(enabled=grad_scaler_enabled, dtype=torch.float16):\n",
        "            outputs = model.base_model.model(**forward_inputs)\n",
        "            loss = outputs.loss / GRAD_ACCUM\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        running += loss.item()\n",
        "        last_step = step\n",
        "\n",
        "        if step % GRAD_ACCUM == 0:\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            scheduler.step()\n",
        "            global_step += 1\n",
        "\n",
        "            avg_loss = running / GRAD_ACCUM\n",
        "            progress_bar.set_postfix({\"loss\": f\"{avg_loss:.3f}\"})\n",
        "            running = 0.0\n",
        "\n",
        "    if last_step % GRAD_ACCUM != 0:\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        scheduler.step()\n",
        "        global_step += 1\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_steps = 0\n",
        "    with torch.no_grad(), torch.cuda.amp.autocast(enabled=grad_scaler_enabled, dtype=torch.bfloat16):\n",
        "        for vb in tqdm(valid_loader, desc=f\"Epoch {epoch + 1} [valid]\", unit=\"batch\"):\n",
        "            vb = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in vb.items()}\n",
        "            vb.pop(\"inputs_embeds\", None)\n",
        "\n",
        "            forward_inputs = {\n",
        "                k: vb[k]\n",
        "                for k in (\"pixel_values\", \"input_ids\", \"attention_mask\", \"position_ids\", \"image_flags\", \"labels\")\n",
        "                if k in vb\n",
        "            }\n",
        "            forward_inputs[\"return_dict\"] = True\n",
        "\n",
        "            outputs = model.base_model.model(**forward_inputs)\n",
        "            val_loss += outputs.loss.item()\n",
        "            val_steps += 1\n",
        "\n",
        "    print(f\"[Epoch {epoch + 1}/{EPOCHS}] valid loss {val_loss / val_steps:.4f}\")\n",
        "    model.train()\n",
        "\n",
        "SAVE_DIR = \"./models/OpenGVLabInternVL2_8B\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "model.save_pretrained(SAVE_DIR)\n",
        "processor.save_pretrained(SAVE_DIR)\n",
        "print(\"Saved:\", SAVE_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZuYBgypVItX"
      },
      "source": [
        "# inference\n",
        "\n",
        "30분~1시간 소요\n",
        "\n",
        "#### 실습 참고 내용\n",
        "\n",
        "    챕터4-1 RAG 기반 Customer Service AI 에이전트 개발\n",
        "    - 데이터 파서 : langchain_core.output_parsers(), StrOutputParser()\n",
        "\n",
        "    챕터 3-1 Transfer Learning 기반의 CNN 모델 학습\n",
        "    - 학습 루프 : 문제 6: 모델 학습을 위한 반복문\n",
        "    - 추론 : with torch.no_grad(), model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "e9500c72c90b4fd8895a6df01666d447",
            "2124455f04414e1da5e7ff7b703b3339",
            "6f7ddb21957145aab6c14c5aaa95e3df",
            "ceab555d4f9345ab96c9ba639b5021d0",
            "ca64964f00464f648a7f96b8d60bcc6f",
            "15a16014e83640348504faa88cd2c0df",
            "23c4fe272b7b4a22bde756f27203acc7",
            "32bb7f0f3d754ee8a437d910c79f0107",
            "e1aa43ab08fc4b719641785916d6b3c0",
            "4504c2efe2ca446d827234680e38de2c",
            "89b4084f14df4ef2944b5c76be8fe07d"
          ]
        },
        "id": "87S01vC0dCmc",
        "outputId": "a4bfbfd0-bebf-4290-b2df-c973587db88e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Inference:   0%|          | 0/972 [00:00<?, ?batch/s]c:\\Users\\SSAFY\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `1e-06` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Inference:   0%|          | 1/972 [00:24<6:33:44, 24.33s/batch]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Inference:   0%|          | 2/972 [00:54<7:31:07, 27.90s/batch]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Inference:   0%|          | 3/972 [01:26<8:01:11, 29.79s/batch]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Inference:   0%|          | 4/972 [01:59<8:21:32, 31.09s/batch]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Inference:   1%|          | 5/972 [02:33<8:35:46, 32.00s/batch]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Inference:   1%|          | 6/972 [03:05<8:36:10, 32.06s/batch]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Inference:   1%|          | 7/972 [03:31<8:01:40, 29.95s/batch]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Inference:   1%|          | 8/972 [04:07<8:31:23, 31.83s/batch]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Inference:   1%|          | 9/972 [04:38<8:31:03, 31.84s/batch]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Inference:   1%|          | 10/972 [05:07<8:15:38, 30.91s/batch]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Inference:   1%|          | 11/972 [05:35<7:58:39, 29.88s/batch]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Inference:   1%|          | 12/972 [06:00<7:35:50, 28.49s/batch]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Inference:   1%|▏         | 13/972 [06:26<7:24:08, 27.79s/batch]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Inference:   1%|▏         | 14/972 [06:51<7:10:17, 26.95s/batch]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Inference:   2%|▏         | 15/972 [07:19<7:12:03, 27.09s/batch]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Inference:   2%|▏         | 16/972 [07:44<7:01:29, 26.45s/batch]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Inference:   2%|▏         | 17/972 [08:07<6:46:16, 25.53s/batch]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Inference:   2%|▏         | 18/972 [08:34<6:51:55, 25.91s/batch]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Inference:   2%|▏         | 19/972 [09:00<6:50:14, 25.83s/batch]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Inference:   2%|▏         | 20/972 [09:23<6:37:44, 25.07s/batch]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Inference:   2%|▏         | 21/972 [09:46<6:27:44, 24.46s/batch]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Inference:   2%|▏         | 22/972 [10:10<6:27:08, 24.45s/batch]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Inference:   2%|▏         | 23/972 [10:37<6:37:50, 25.15s/batch]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Inference:   2%|▏         | 24/972 [11:01<6:29:10, 24.63s/batch]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Inference:   3%|▎         | 25/972 [11:26<6:31:15, 24.79s/batch]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Inference:   3%|▎         | 26/972 [11:53<6:40:33, 25.41s/batch]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Inference:   3%|▎         | 27/972 [12:22<7:01:09, 26.74s/batch]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Inference:   3%|▎         | 28/972 [12:46<6:44:24, 25.70s/batch]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Inference:   3%|▎         | 29/972 [13:16<7:05:23, 27.07s/batch]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Inference:   3%|▎         | 30/972 [13:40<6:52:19, 26.26s/batch]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Inference:   3%|▎         | 31/972 [14:12<7:16:15, 27.82s/batch]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Inference:   3%|▎         | 32/972 [14:45<7:40:03, 29.36s/batch]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Inference:   3%|▎         | 33/972 [15:13<7:34:31, 29.04s/batch]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Inference:   3%|▎         | 34/972 [15:38<7:16:02, 27.89s/batch]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Inference:   4%|▎         | 35/972 [16:03<6:59:06, 26.84s/batch]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Inference:   4%|▎         | 35/972 [16:38<7:25:36, 28.53s/batch]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     32\u001b[39m batch = {k: v.to(device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch.items()}\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     out_ids = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprocessor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m decoded = processor.batch_decode(out_ids, skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     41\u001b[39m preds.extend(extract_choice(text) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m decoded)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SSAFY\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\peft\\peft_model.py:1973\u001b[39m, in \u001b[36mPeftModelForCausalLM.generate\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1971\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._enable_peft_forward_hooks(*args, **kwargs):\n\u001b[32m   1972\u001b[39m         kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.special_peft_forward_args}\n\u001b[32m-> \u001b[39m\u001b[32m1973\u001b[39m         outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1974\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1975\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.base_model.generate(**kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SSAFY\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SSAFY\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:2223\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[39m\n\u001b[32m   2215\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2216\u001b[39m         input_ids=input_ids,\n\u001b[32m   2217\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   2218\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2219\u001b[39m         **model_kwargs,\n\u001b[32m   2220\u001b[39m     )\n\u001b[32m   2222\u001b[39m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2223\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2224\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2225\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2226\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2227\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2228\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2229\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2230\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2231\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2233\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2234\u001b[39m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[32m   2235\u001b[39m     beam_scorer = BeamSearchScorer(\n\u001b[32m   2236\u001b[39m         batch_size=batch_size,\n\u001b[32m   2237\u001b[39m         num_beams=generation_config.num_beams,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2242\u001b[39m         max_length=generation_config.max_length,\n\u001b[32m   2243\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SSAFY\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:3200\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   3197\u001b[39m         model_forward = \u001b[38;5;28mself\u001b[39m.get_compiled_call(generation_config.compile_config)\n\u001b[32m   3199\u001b[39m is_prefill = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3200\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_unfinished_sequences(\n\u001b[32m   3201\u001b[39m     this_peer_finished, synced_gpus, device=input_ids.device, cur_len=cur_len, max_length=max_length\n\u001b[32m   3202\u001b[39m ):\n\u001b[32m   3203\u001b[39m     \u001b[38;5;66;03m# prepare model inputs\u001b[39;00m\n\u001b[32m   3204\u001b[39m     model_inputs = \u001b[38;5;28mself\u001b[39m.prepare_inputs_for_generation(input_ids, **model_kwargs)\n\u001b[32m   3206\u001b[39m     \u001b[38;5;66;03m# prepare variable output controls (note: some models won't accept all output controls)\u001b[39;00m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# 데이터 파서 : 모델의 응답에서 선지를 추출\n",
        "def extract_choice(text: str) -> str:\n",
        "    text = text.strip().lower()\n",
        "\n",
        "    lines = [l.strip() for l in text.splitlines() if l.strip()]\n",
        "    if not lines:\n",
        "        return \"a\"\n",
        "    last = lines[-1]\n",
        "    if last in [\"a\", \"b\", \"c\", \"d\"]:\n",
        "        return last\n",
        "\n",
        "    tokens = last.split()\n",
        "    for tok in tokens:\n",
        "        if tok in [\"a\", \"b\", \"c\", \"d\"]:\n",
        "            return tok\n",
        "    return \"a\"\n",
        "\n",
        "# 테스트 데이터 준비\n",
        "test_ds = VQAMCDataset(test_df, processor, train=False)\n",
        "test_loader = DataLoader(\n",
        "    test_ds,\n",
        "    batch_size=4,  # GPU 여유에 맞춰 조절\n",
        "    shuffle=False,\n",
        "    collate_fn=DataCollator(processor, train=False, add_generation_prompt=True),\n",
        "    num_workers=0,\n",
        ")\n",
        "\n",
        "model.eval()\n",
        "preds = []\n",
        "\n",
        "for batch in tqdm(test_loader, desc=\"Inference\", unit=\"batch\"):\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    with torch.no_grad():\n",
        "        out_ids = model.generate(\n",
        "            **batch,\n",
        "            max_new_tokens=2,\n",
        "            do_sample=False,\n",
        "            eos_token_id=processor.tokenizer.eos_token_id,\n",
        "        )\n",
        "    decoded = processor.batch_decode(out_ids, skip_special_tokens=True)\n",
        "    preds.extend(extract_choice(text) for text in decoded)\n",
        "\n",
        "submission = pd.DataFrame({\"id\": test_df[\"id\"], \"answer\": preds})\n",
        "submission.to_csv(\"/content/submission.csv\", index=False)\n",
        "print(\"Saved /content/submission.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1vV5fJViJGZ",
        "outputId": "1a87d503-0e47-49b2-a3e0-b9d565f95ce5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "system\n",
            "You are a helpful visual question answering assistant. Answer using exactly one letter among a, b, c, or d. No explanation.\n",
            "user\n",
            "이 사진의 주요 상황은 무엇인가요?\n",
            "(a) 수업 시간에 공부하고 있다\n",
            "(b) 회의에 참석하고 있다\n",
            "(c) 졸업식 준비 중이다\n",
            "(d) 시험을 치르고 있다\n",
            "\n",
            "정답을 반드시 a, b, c, d 중 하나의 소문자 한 글자로만 출력하세요.\n",
            "assistant\n",
            "c\n"
          ]
        }
      ],
      "source": [
        "# 모델 응답 예시\n",
        "# print(output_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PY: c:\\Users\\SSAFY\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\n",
            "torch: 2.6.0+cu124\n",
            "torch.version.cuda: 12.4\n",
            "is_available: True\n",
            "GPU: NVIDIA GeForce RTX 3050 OEM\n"
          ]
        }
      ],
      "source": [
        "import torch, sys\n",
        "print(\"PY:\", sys.executable)\n",
        "print(\"torch:\", torch.__version__)\n",
        "print(\"torch.version.cuda:\", torch.version.cuda)\n",
        "print(\"is_available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\"c:\\Users\\SSAFY\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\" -m pip uninstall -y torch torchvision torchaudio\n",
        "\"c:\\Users\\SSAFY\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\" -m pip install --index-url https://download.pytorch.org/whl/cu124 torch torchvision torchaudio"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01fd5c7afa1448be9eced088b534094d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1302a6526a844fe9b7bdad7d422449a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "15a16014e83640348504faa88cd2c0df": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1716f42191b441939e4bc3b6c771fa63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a96441f9d5d43aab8466a9bf13c4cdd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e05d94757014640b1f0a4ba7e13cd25": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2124455f04414e1da5e7ff7b703b3339": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15a16014e83640348504faa88cd2c0df",
            "placeholder": "​",
            "style": "IPY_MODEL_23c4fe272b7b4a22bde756f27203acc7",
            "value": "Inference: 100%"
          }
        },
        "23c4fe272b7b4a22bde756f27203acc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26fc51d519a34e148ac30ea2984ce2f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2900d4c8a80e43da80988161daa92df3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32bb7f0f3d754ee8a437d910c79f0107": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "403bef8878f147deb789233e0bdbdafb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4504c2efe2ca446d827234680e38de2c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4767df1e8b7e43ee8b466dfe087b1ef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3dc16bc47a346029d42c78c27f26f77",
            "placeholder": "​",
            "style": "IPY_MODEL_c60f821626fb4b53beeb0499ac113113",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "51666bc88ac943f7b8aaf46bc9c5cd7a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d4ba90bb49c4f2c8ae8c71032e061dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a96441f9d5d43aab8466a9bf13c4cdd",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94396c8893eb46fdac64d7ea5a02c9a2",
            "value": 2
          }
        },
        "6195d11a117141fabfb5e9774ef81d3c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dafd6a2188d4e448ec077630a9d7d20": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4767df1e8b7e43ee8b466dfe087b1ef4",
              "IPY_MODEL_5d4ba90bb49c4f2c8ae8c71032e061dd",
              "IPY_MODEL_c681a9babaac4fc4b01ed90aaa8367ae"
            ],
            "layout": "IPY_MODEL_51666bc88ac943f7b8aaf46bc9c5cd7a"
          }
        },
        "6f7ddb21957145aab6c14c5aaa95e3df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32bb7f0f3d754ee8a437d910c79f0107",
            "max": 3887,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1aa43ab08fc4b719641785916d6b3c0",
            "value": 3887
          }
        },
        "7684d714a6ea421eb3acbe8a4ad41379": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26fc51d519a34e148ac30ea2984ce2f9",
            "placeholder": "​",
            "style": "IPY_MODEL_403bef8878f147deb789233e0bdbdafb",
            "value": "Epoch 1 [train]: 100%"
          }
        },
        "7b722009deaf463eaf6a6f1a199d0544": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d74fa2a26174f83a064c7f4f37d2a0b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "840e1478cf0f41e9907110685c5b306a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7684d714a6ea421eb3acbe8a4ad41379",
              "IPY_MODEL_ff9e6154da0e4a06a8f31563ae43bbef",
              "IPY_MODEL_b664fb63691a4a7680a2cbb5c20b08b9"
            ],
            "layout": "IPY_MODEL_6195d11a117141fabfb5e9774ef81d3c"
          }
        },
        "8534de244cab4c74aeae82c05ac6132e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4775ec0fb8643daa4dcaede2b20c164",
            "placeholder": "​",
            "style": "IPY_MODEL_1716f42191b441939e4bc3b6c771fa63",
            "value": "Epoch 1 [valid]: 100%"
          }
        },
        "89b4084f14df4ef2944b5c76be8fe07d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a6f1e76a2b04e4581ccb0247bae372a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94396c8893eb46fdac64d7ea5a02c9a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9752fdd498724b61ba90dbd5e8e09c1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8534de244cab4c74aeae82c05ac6132e",
              "IPY_MODEL_9bf9592ce2134d409e1748e905b3dd62",
              "IPY_MODEL_f8f66e57dbdf4147aebb05df460f87f1"
            ],
            "layout": "IPY_MODEL_1e05d94757014640b1f0a4ba7e13cd25"
          }
        },
        "9bf9592ce2134d409e1748e905b3dd62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b722009deaf463eaf6a6f1a199d0544",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_baaed15657a94169abe754873570ae8e",
            "value": 20
          }
        },
        "a13bc776ff074560a704aa9d601985d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af68f248e2804569bae5ab7d8ede79e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b664fb63691a4a7680a2cbb5c20b08b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d74fa2a26174f83a064c7f4f37d2a0b",
            "placeholder": "​",
            "style": "IPY_MODEL_01fd5c7afa1448be9eced088b534094d",
            "value": " 180/180 [11:45&lt;00:00,  3.63s/batch, loss=1.456]"
          }
        },
        "baaed15657a94169abe754873570ae8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c60f821626fb4b53beeb0499ac113113": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c681a9babaac4fc4b01ed90aaa8367ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a13bc776ff074560a704aa9d601985d2",
            "placeholder": "​",
            "style": "IPY_MODEL_2900d4c8a80e43da80988161daa92df3",
            "value": " 2/2 [00:34&lt;00:00, 17.24s/it]"
          }
        },
        "ca64964f00464f648a7f96b8d60bcc6f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ceab555d4f9345ab96c9ba639b5021d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4504c2efe2ca446d827234680e38de2c",
            "placeholder": "​",
            "style": "IPY_MODEL_89b4084f14df4ef2944b5c76be8fe07d",
            "value": " 3887/3887 [53:51&lt;00:00,  1.30sample/s]"
          }
        },
        "e1aa43ab08fc4b719641785916d6b3c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3dc16bc47a346029d42c78c27f26f77": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4775ec0fb8643daa4dcaede2b20c164": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9500c72c90b4fd8895a6df01666d447": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2124455f04414e1da5e7ff7b703b3339",
              "IPY_MODEL_6f7ddb21957145aab6c14c5aaa95e3df",
              "IPY_MODEL_ceab555d4f9345ab96c9ba639b5021d0"
            ],
            "layout": "IPY_MODEL_ca64964f00464f648a7f96b8d60bcc6f"
          }
        },
        "f8f66e57dbdf4147aebb05df460f87f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af68f248e2804569bae5ab7d8ede79e8",
            "placeholder": "​",
            "style": "IPY_MODEL_fdd9d824e75b4f478a6c0f3b3cd4e8ab",
            "value": " 20/20 [00:38&lt;00:00,  1.91s/batch]"
          }
        },
        "fdd9d824e75b4f478a6c0f3b3cd4e8ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff9e6154da0e4a06a8f31563ae43bbef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a6f1e76a2b04e4581ccb0247bae372a",
            "max": 180,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1302a6526a844fe9b7bdad7d422449a7",
            "value": 180
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
